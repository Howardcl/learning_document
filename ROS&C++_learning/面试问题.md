## 一. 编译原理

### 1. **程序编译的过程**

**程序转换为机器码要经历四个过程：预处理、编译、汇编、链接。**

![image-20210820222751378](https://i.loli.net/2021/08/20/g9muKOkt18j3Trh.png)

```shell
// 预处理： g++ -E main.cpp > main.i (宏替换，注释消除)
// 编译：   g++ -S main.cpp（.s文件是汇编文件）
// 汇编：   g++ -c main.cpp（.o文件是目标文件，里面是二进制机器码）
// 链接：   g++ -o main main.cpp（将多个.o文件合成执行文件）


      预处理器     编译器      汇编器      链接器
 .cpp  ————>  .i  ————>  .s  ————>  .o  ————> 可执行目标程序
(源程序) （被修改的源程序）（汇编程序）（可重定位目标程序）    
```

![image-20210829180622041](https://i.loli.net/2021/08/29/tZLUYhgmCw1nRQf.png)

**为什么要有这四个过程？**

`.cpp`程序是高级语言程序，让人容易理解，但是无法直接驱动硬件CPU直接执行（只能理解二进制代码）。为了使程序可以被执行，驱动硬件电路工作，必须经过一些处理步骤将其转化为可执行性的目标程序（二进制代码）。

> **（1）预处理**

预处理器只不过是一个文本替换工具而已，所有的预处理命令都是以#开头的。

宏替换（系统不为#define定义的常量分配内存）；删除所有注释；处理条件编译指令、预编译指令

<img src="https://i.loli.net/2021/08/29/XZBK4Ramsof5Q13.png" alt="image-20210820130405989" style="zoom:67%;" />

> **（2）编译**

识别语法，数据类型，逐行逐句检查，将源程序转换为汇编程序。

> **（3）汇编**

将汇编程序转换为机器码

> **（4）链接**

将外部函数库拷贝到可执行文件中（**这是静态链接**），在内存中进行。

**程序编译时是不分配内存的。**

### 2. **静态链接 vs 动态链接** 

> **什么是库？**

库是现成的，成熟的，可以复用的代码。本质上来说，**库是一种可执行代码的二进制形式，可以被操作系统载入内存执行。**库有两种：静态库和动态库。所谓静态、动态是指链接。

源程序经历预处理、编译、汇编和链接之后就可以运行了。至于运行期间发生的事情与编译器一概无关。但是开发者可以在编译阶段选择可执行文件链接外部函数库的方式，是静态链接（编译时链接）还是动态链接（运行时链接）。

> **静态链接**

- 静态链接库文件后缀：`.lib` 和 `.a`

- 链接时机：编译时期
- 链接方式：将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中。
- 优点：程序在运行时与函数库再无瓜葛，移植方便
- 缺点：（1）静态库在内存中存在多份拷贝，浪费空间和资源；（2）更新程序麻烦，如果静态库更新了，使用它的应用程序都需要重新编译。

试想一下，静态库和汇编生成的目标文件一起链接为可执行文件，那么静态库必定与 `.o` 文件格式相似。其实一个静态库可以简单看作是一组目标文件（`.o / .obj`文件）的集合，即很多目标文件经过压缩打包后形成的一个文件。

为什么需要动态库？因为静态库浪费空间。

> **动态链接**

- 动态链接库文件后缀：Linux平台 — `.so`，Windows平台 —  `.dll`，Mac平台 — `.dylib`（动态库也称共享库）

- 链接时机：运行时
- 链接方式：程序编译时不会被链接到目标代码中，而是在程序运行时才被载入
- 优点：（1）不同的应用程序如果调用相同的库，内存中只需要一份该共享库的实例，规避了空间浪费问题；（2）动态库在运行时才被载入，如果动态库更新了，使用它的应用程序无需重新编译；（3）可以实现进程之间的资源共享
- 缺点：用户必须实现安装好库文件，且版本和安装位置都必须符合要求，否则无法正常运行。

**静态库和动态库的区别在于库函数被载入的时机不同。**



### 3. 编译运行时的内存情况

- 编译后运行前

  编译后不分配内存，生成的可执行文件存放在磁盘上。代码区和全局区都是程序在运行前划分好的两个区域，程序运行后才有栈区和堆区。

- 运行

  运行时必分配内存，因为 CPU 只与内存打交道。当运行可执行文件时，程序被加载到内存中，成为进程。

### 4. 函数调用

函数调用的过程：

（1）名字查找

（2）重载决议

（3）可访问性检查。

```C++
class myClass
{
public:
    myClass() {}
    double func(double n) { return n; }
private:
    int func(int n) { return n; }
};


int main()
{
    myClass mc;
    mc.func(7);  //报错

    return 0;
}
```

上面的程序在编译过程中会报错，原因如下：

编译器在对`func(7)` 这个调用进行决议时，主要做了三件事情，依次如下：

- **名字查找：**编译器会首先查找所有函数名为`func`的函数作为候选，查找时不受访问权限的限制，也就是说候选列表中有`func(double)`和`func(int)`两个函数。
- **重载决议：**目的是在候选列表中找到唯一一个最佳匹配，程序中的参数为 7，是 int，所以选择的函数为`func(int)`。
- **可访问性检查：**编译器进行访问性检查，确定被选用的函数能否被调用。在进行可访问性检查时发现，`func(int)`函数处于`private`作用域中，不能被调用，所以在对`func(7)`进行调用时会报错。

```C++
class myClass
{
public:
    myClass() {}
    double func(double n) { return n; }
private:
    unsigned func(unsigned n) { return n; }  //不是int而是unsigned
};

int main()
{
    myClass mc;
    mc.func(7);  //报错

    return 0;
}
```

在调用`func(7)`时同样会进行上述的三步决议，

- 名字查找：找到`func(double)`和`func(unsigned)`两个函数。
- 重载决议：由于 7 是 int 类型，在函数列表中没有一个函数与之匹配，所以出现二义性，即编译器也不知道选择哪个函数比较好。所以在重载决议时就会发生错误
- 可访问性检测：显然还没有检测可访问性就已经出错
  编译过程会报错：对重载函数的调用不明确。

```C++
#include <string>

int func(int);  //全局函数

class myClass
{
public:
    double test()
    {
        return func(7); //调用哪个？
    }   

private:
    std::string func(std::string)   //类内部函数
    {
        return "hello world!";
    }
};


int main()
{
    myClass mc;
    mc.test();
}
```

这个程序包含一个全局函数`func(int)`，一个类内部的函数`func(std::string)`，程序通过`test`接口调用`func(7)`函数，同样也需要进行决议：

- 名字查找：名字查找的规则是**倘若在一个作用域中找到至少一个名字匹配的函数，就不再去外层作用域中进行寻找**。本程序中首先在类内部作用域中寻找，找到`std::string func(std::string)`函数，而后停止。换句话说，候选函数只有`func(std::string)`一个，而没有`func(int)`;
- 重载决议：7 是 int 类型，候选函数列表中没有与之匹配或者可以进行转换的函数，导致在重载决议处发生错误。
- 可访问性检测：仍然没有进行到这里。
  编译过程会报错：没有从 int 到 std::string 的适当转换。

### 5. C 语言为何不支持重载？

什么是函数重载？

在同一作用域类，一组函数的函数名相同，参数列表不同（个数不同/类型不同），返回值可同可不同。

![这里写图片描述](https://www.freesion.com/images/161/1b71f320f94f4933f034f89c7df93f51.JPEG)

其实是这样，C++在编译时会对函数名进行优化，对于参数不同的同名函数对应的优化后的函数`_Z[N][fun][list]`

```
N：代表函数名长度
fun：函数名
list：所有参数的首字母
```

例如上面那段代码在`linux`下编译成目标文件，再使用nm指令查看符号信息如下图：

![这里写图片描述](https://i.loli.net/2021/10/09/fB9W3jDmKEl4Th2.jpg)

**名字修饰内容**

- 在C语言中，编译器在编译过程会将我们的函数重命名，具体的方法就是在我们的函数名前加上“_“修饰符，通过这种方式就可以在我们的符号表中查找到了，但是假如有两个相同的函数，编译之后进行相同的重命名，在符号表中生成的函数名一样，那么就无法区分到底是哪个函数了，所以这也就是我们的C语言为什么不支持函数重载的原因了。
- 在C++中，既然支持函数重载，那么它肯定对C语言在这方面进行了优化，具体的方法就是**在函数名后面加上参数**然后生成我们符号表中的函数名称。那么这样一来，就很容易理解了，为什么 C++ 可以支持函数重载了，就是因为函数重载底层的原理造成的，就是由于重载函数在符号表中生成的函数名称不一样，这样就能区分到底是哪个函数了。这样一来编译就能通过了。
- C++ 能否按照 C 语言的方式来编译文件
  答案是肯定可以的，只需要在我们的函数前加上 extern ”C“ 即可。例如
  extern "C" int add(int a,int b){
  	return a + b;
  }

### 6. 调试工具 `GDB`

- 调试启动无参程序

  ```shell
  gdb hello
  (gdb)run
  ```

- 调试启动带参程序

  编译：

  ```shell
  gcc -g -o hello hello.c
  ```

  启动调试（带有参数）

  ```shell
  gdb hello
  (gdb)run 参数
  或者先 set args 参数，再 run
  ```

- 调试 core 文件

  当程序 core dump 时，可能会产生 core 文件，它能够帮助定位问题，但前提是系统没有限制 core 文件的产生，可以使用命令 limit -c 查看：

  ```shell
  ulimit -c
  ```

  如果结果是0，即便程序 core dump 了也不会留下 core 文件，需要让 core 文件能够产生：

  ```shell
  ulimit -c unlimied  # 表示不限制 core 文件大小
  或者
  ulimit -c 10        # 指定最大大小，单位为块，一块默认为512字节
  ```

  调试 core 文件：

  ```shell
  gdb 程序文件名 core文件名
  ```

- 调试已运行程序

  使用 ps 命令找到进程 id

  ```shell
  ps -ef|grep 进程名、
  或者
  pidof 进程名
  ```

  获取到进程 id 后，开始调试进程：

  ```shell
  gdb
  (gdb) attach 进程id
  ```

- 设置断点

  ```shell
  # 查看已设置的断点
  info breakpoints
  
  # 根据行号设置断点
  b 9  # break 可简写为 b
  b hello.c:9
  
  # 根据函数名设置断点
  b printNum
  
  # 根据条件设置断点
  b hello.c:9 if b==0  # 当在b等于0时，程序将会在第23行断住
  # 它和condition有着类似的作用，假设上面的断点号为1，那么：
  condition 1 b==0
  # 会使得b等于0时，产生断点1。而实际上可以很方便地用来改变断点产生的条件，例如，之前设置b==0时产生该断点，那么使用condition可以修改断点产生的条件。
  
  #根据规则设置断点
  #例如需要对所有调用printNum函数都设置断点，可以使用下面的方式：
  rbreak printNum*
  #所有以printNum开头的函数都设置了断点。而下面是对所有函数设置断点：
  #用法：rbreak file:regex
  rbreak . 
  rbreak test.c:.        #对test.c中的所有函数设置断点
  rbreak test.c:^print   #对以 print 开头的函数设置断点
  
  #设置临时断点
  #假设某处的断点只想生效一次，那么可以设置临时断点，这样断点后面就不复存在了：
  tbreak test.c:l0  #在第10行设置临时断点
  
  #跳过多次设置断点
  #假如有某个地方，我们知道可能出错，但是前面30次都没有问题，虽然在该处设置了断点，但是想跳过前面30次，可以使用下面的方式：
  ignore 1 30
  #其中，1是你要忽略的断点号，可以通过前面的方式查找到，30是需要跳过的次数。这样设置之后，会跳过前面30次。再次通过info breakpoints可以看到：
  Num     Type           Disp Enb Address            What
  1       breakpoint     keep y   0x00000000004005e8 in printNum2 at test.c:16
      ignore next 30 hits
      
  #根据表达式值变化产生断点
  #有时候我们需要观察某个值或表达式，知道它什么时候发生变化了，这个时候我们可以借助watch命令。例如：
  watch a
  #这个时候，让程序继续运行，如果a的值发生变化，则会打印相关内容，如：
  Hardware watchpoint 2: a
  Old value = 12
  New value = 11
  #但是这里要特别注意的是，程序必须运行起来，否则会出现：
  No symbol "a" in current context.
  #因为程序没有运行，当前上下文也就没有相关变量信息。
  
  
  #禁用或启动断点
  #有些断点暂时不想使用，但又不想删除，可以暂时禁用或启用。例如：
  disable             #禁用所有断点
  disable bnum        #禁用标号为bnum的断点
  enable              #启用所有断点
  enable bnum         #启用标号为bnum的断点
  enable delete bnum  #启动标号为bnum的断点，并且在此之后删除该断点
  
  #断点清除
  #断点清除主要用到clear和delete命令。常见使用如下：
  clear                   #删除当前行所有breakpoints
  clear function          #删除函数名为function处的断点
  clear filename:function #删除文件filename中函数function处的断点
  clear lineNum           #删除行号为lineNum处的断点
  clear f:lename：lineNum #删除文件filename中行号为lineNum处的断点
  delete                  #删除所有breakpoints,watchpoints和catchpoints
  delete bnum             #删除断点号为bnum的断点
  ```

- 查看变量

  最常见的使用便是使用print（可简写为p）打印变量内容。
  例如，打印基本类型，数组，字符数组等直接使用p 变量名即可：

  ```text
  (gdb) p a
  $1 = 10
  (gdb) p b
  $2 = {1, 2, 3, 5}
  (gdb) p c
  $3 = "hello,shouwang"
  (gdb) 
  ```

  当然有时候，多个函数或者多个文件会有同一个变量名，这个时候可以在前面加上函数名或者文件名来区分：

  ```text
  (gdb) p 'testGdb.h'::a
  $1 = 11
  (gdb) p 'main'::b
  $2 = {1, 2, 3, 5}
  (gdb) 
  ```

  ### **打印指针指向内容**

  如果还是使用上面的方式打印指针指向的内容，那么打印出来的只是指针地址而已，例如：

  ```text
  (gdb) p d
  $1 = (int *) 0x602010
  (gdb) 
  ```

  而如果想要打印指针指向的内容，需要解引用：

  ```text
  (gdb) p *d
  $2 = 0
  (gdb) p *d@10
  $3 = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
  (gdb) 
  ```

  从上面可以看到，仅仅使用*只能打印第一个值，如果要打印多个值，后面跟上@并加上要打印的长度。或者@后面跟上变量值：

  ```text
  (gdb) p *d@a
  $2 = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
  (gdb) 
  ```

  由于a的值为10，并且是作为整型指针数据长度，因此后面可以直接跟着a，也可以打印出所有内容。

  另外值得一提的是，$可表示上一个变量，而假设此时有一个链表 linkNode，它有next成员代表下一个节点，则可使用下面方式不断打印链表内容：

  ```text
  (gdb) p *linkNode
  (这里显示linkNode节点内容)
  (gdb) p *$.next
  (这里显示linkNode节点下一个节点的内容)
  ```

  如果想要查看前面数组的内容，你可以将下标一个一个累加，还可以定义一个类似UNIX环境变量，例如：

  ```text
  (gdb) set $index=0
  (gdb) p b[$index++]
  $11 = 1
  (gdb) p b[$index++]
  $12 = 2
  (gdb) p b[$index++]
  $13 = 3
  ```

  这样就不需要每次修改下标去打印啦。

- 查看堆栈信息 `backtrace`，缩写为`bt`

  堆栈中的每个函数都被分配了一个编号，最近被调用的函数在 0 号帧中（栈顶）。`bt n`表示只打印栈顶上 n 层的栈信息；`bt -n`表示只打印栈底 n 层的信息。

- 

## 二. 内存管理

### 1. 内存四区

内存四区是虚拟内存层面的概念，大致分为4个区域：代码区，全局区，栈区，堆区。

- **代码区**：存放函数体的二进制代码，由**操作系统**进行管理；    

- **全局区（静态区）**：存放全局变量和静态变量以及常量；

```
1> data 区: data 区里主要存放的是已经初始化的非零全局变量、静态变量和常量
2> bss 区: bss 区主要存放的是未初始化的/初始化为0的全局变量、静态变量，这些未初始化的数据在程序执行前会自动被系统初始化为 0 或者 NULL；
3> 常量区:常量区是全局区中划分的一个小区域，里面存放的是常量，如 const 修饰的全局变量、字符串常量等   
```

- **栈区**：程序局部变量区。由**编译器自动分配释放**（先进后出），存放函数的参数值，局部变量等。    

- **堆区**：由**程序员分配和释放**，若程序员不释放，程序结束时由操作系统回收    C\C++ 既可以在栈上分配内存，又可以在堆上分配内存        

text 和 data 段都在可执行文件中，由系统从可执行文件中加载，bss 段不在可执行文件中，也就是说 bss 段不为数据分配。

**意义**：不同区域存放的数据，赋予不同的生命周期，给与更大的灵活编程。

​    

- 程序运行前：在程序编译后，会生成可执行程序，在没有执行该程序之前会被分为两个区域。
  - 代码区：
    - 存放 CPU 执行的机器指令
    - 代码区是共享且只读的：目的是节省内存和防止意外修改
  - 全局区：
    - **全局变量**与**静态变量（static）**存放于此
    - **常量区**：字符串常量与其他常量存放于此
    - 程序结束后由操作系统进行释放

- 程序运行后：
  - 栈区：编译器自动分配释放
  - 堆区：程序员手动分配释放

### 2. 堆 vs 栈

- 内存四区的组成之二【全局区（静态区）、代码区、**栈区、堆区**】



**堆和栈的区别**

- **申请方式**
  - 栈：由系统自动分配。 
  - 堆：需要程序员自己申请，并指明大小，
    - 在 `C` 中 `malloc` **函数**；
      在 `C++`中用 `new` **关键字**；
- **申请后操作系统的响应**
  - 栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。
  - 堆：【操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序】（会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的 delete 语句才能正确的释放本内存空间）。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。
- **申请大小的限制**
  - 栈：[生长方向：从高到低，**连续**的内存区域]。栈顶的地址和栈的最大容量是系统预先规定好的，在`windows`下，栈的大小是 `2M`（也有的说是 `1M`，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示 `overflow`。因此，能从栈获得的空间较小。
  - 堆：[生长方向：从低到高，**不连续**的内存区域（由于系统是**用链表来存储**的空闲内存地址的，自然是不连续的）]。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。
- **申请效率的比较**
  - 栈：栈由系统自动分配，速度较快。但程序员是无法控制的。
  - 堆：由 `new` 分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便。（`windows` 下，最好的方式是用 `VirtualAlloc` 分配内存，他不是在堆，也不是在栈，是直接在进程的地址空间中保留一块内存，虽然用起来最不方便。但是速度快，也最灵活。）
- **堆和栈中的存储内容**
  - 栈： 在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的**(指令)地址**，然后是**函数的各个参数**【在大多数的`C`编译器中，参数是**由右往左**入栈的】，然后是函数中的**局部变量**。注意静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。
  - 堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。
- **存取效率的比较**
  - ？？？



- **栈溢出如何引起？如何解决？**

  （这里的溢出是指上溢，满了放不下了；下溢是指空了没东西可取了）

  - 引起原因：栈一般默认为`1 ~ 2M`，一旦出现**死循环**或者是**递归层次太深/函数调用层过深**，在不断的压栈过程中，造成栈容量超过`1M`而导致溢出。

  - 解决方案：

    （1）将递归转换为非递归；

    （2）使用`static`对象替代`nonstatic`局部对象；

    （3）增大堆栈大小

### 3. 内存溢出 vs 泄露

- **内存溢出**

  申请的内存空间超出了系统实际分配的内存空间。

  原因：内存中加载的数据量过大，比如说从数据库中取出过多数据，集合类中有对对象的引用，使用完后未清空，使得不能回收，代码中存在死循环，或者循环产生过多重复的对象实体，使用的第三方软件中的 BUG 启动参数内存值设定的过小。

- **内存泄露**

  用户动态分配的内存使用完后没有释放，当指向这块内存的指针的生命周期结束后，就找不到这块内存了，失去了对它的控制，造成了内存浪费。

  预防的方法：

  - 养成良好的习惯：申请后一定要释放（`malloc()` 和 `free()`函数配对，`new`和`delete`关键字配对），释放后马上将指针指向 `nullptr`，避免野指针；

  - 使用 **`RAII`** 机制，在类的构造函数中申请内存，在析构函数中释放内存，利用了类的特性：实例化对象时自动调用构造函数，对象在作用域外会自动得以析构；
  - 父类的析构函数一定要定义为虚函数
  - 使用**智能指针**

**内存泄漏的定位方法：**

如果程序中存在内存泄漏，我们的目的是找到这些内存是在哪里分配的。内存在哪里释放的我们没必要监测，只需要检测出内存是在哪里申请的即可，如何检测呢？

定位原理的关键是检查 `malloc/new` 与 `free/delete` 是否匹配

- 自己封装 `malloc` 和 `new`
- 使用工具`valgrind`、`mtrace`、`debug_new`
-  使用宏覆盖 `malloc`和`free`函数，或者使用`malloc`和`free`的钩子

**整体思路很简单**：在申请内存时记录下该内存的地址和在代码中申请内存的位置，在内存销毁时删除该地址对应的记录，程序最后统计下还有哪条记录没有被删除，如果还有没被删除的记录就代表有内存泄漏。

new关键字更底层是通过operator new来申请内存的：

```cpp
void* operator new(std::size_t sz)
```

也就是C++都是通过`operator new(std::size_t sz)`来申请内存，而这个操作符可以重载：

```cpp
void* operator new(std::size_t size, const char* file, int line);
void* operator new[](std::size_t size, const char* file, int line);
```

如果能让程序申请内存时调用重载的这个函数，就可以记录下内存申请的具体位置啦。

怎么能够让底层程序申请内存时调用重载的这个函数呢？这里可以对new使用宏定义：

```cpp
#define new new (__FILE__, __LINE__)
```

有了这个宏定义后，在`new`的时候底层就会自动调用`operator new(std::size_t size, const char* file, int line)`函数，至此达到了我们记录内存申请位置的目的。

### 4. `malloc`  vs `new`

- 属性

  `new` 和 `delete`是 `C++`**关键字**，需要编译器支持；

  `malloc `和 `free`是**库函数**，需要头文件支持 `<memory>`。

- 参数

  `new`操作符申请内存分配时**无须指定内存块的大小**，编译器会根据类型信息自行计算

  （`A* p = new A ==> 第一步 void* mem = operator new(sizeof(A))`）。

  而`malloc`则需要**显式地指出所需内存的尺寸**。

- 返回类型

  `new`操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故`new`是符合**类型安全性的操作符**。

  （第二步 `A* p = static_cast<A*>mem; `）

  而`malloc`内存分配成功则是返回`void *` ，需要通过强制类型转换将`void*`指针转换成我们需要的类型。

- 自定义类型

  **`new`**会先调用`operator new`函数，申请足够的内存（通常底层使用`malloc`实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。**`delete`**先调用析构函数，然后调用`operator delete`函数释放内存（通常底层使用`free`实现）`malloc/free`是库函数，只能动态的申请和释放内存，**无法强制要求其做自定义类型对象构造和析构工作**。

- 重载

  `C++`允许重载`operator new` 和 `operator delete` 函数控制动态内存的分配（最好在类里面重载，注意，一定要定义为静态成员函数，因为在`new`之前对象还没有被构造出来，无法调用非静态函数，不建议全局重载）。

- 内存区域

  ① `new`做两件事：分配内存和调用类的构造函数，`delete`是：调用类的析构函数和释放内存。

  ② `malloc`和`free`只是分配和释放内存。

  `new`操作符从**自由存储区（free store）**上为对象动态分配内存空间

  `malloc`函数从**堆上**动态分配内存。

  【**补充**：自由存储区是`C++`基于`new`操作符的一个抽象概念，凡是通过`new`操作符进行内存申请，该内存即为自由存储区；

  堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，

​		**自由存储区不等于堆**，如上所述，布局`new`就可以不位于堆中】

- 分配失败

  `new`内存分配失败时，会**抛出`bac_alloc`异常**。

  `malloc`分配内存失败时**返回`NULL`**。

- 内存泄漏【可以不说】

  内存泄漏对于`new`和`malloc`都能检测出来，而`new`可以指明是哪个文件的哪一行，`malloc`确不可以。

### 4. `malloc` 底层实现

`void* malloc(size_t size);` 

`void free(void* ptr);`

`malloc`采用推进`brk`指针来增加堆的有效区域来申请内存空间分配内存，维护一个内存空闲链表，当申请内存空间时，（**伙伴系统**）搜索内存空闲链表，找到适配的空闲内存空间，然后将空间分割成两个内存块，一个变成分配块，一个变成新的空闲块。如果没有搜索到，那么就会用`sbrk()`才推进`brk`指针来申请内存空间。

`malloc/free`的实现过程：

1、空闲存储空间以**空闲链表**的方式组织（地址递增），每个块包含一个长度、一个指向下一块的指针以及一个指向自身存储空间的指针。（ 因为程序中的某些地方可能不通过`malloc`调用申请，因此`malloc`管理的空间不一定连续。）

2、当有申请请求时，`malloc`会扫描**空闲链表**，直到找到一个足够大的块为止（首次适应）(因此每次调用`malloc`时并不是花费了完全相同的时间）。

3、如果该块恰好与请求的大小相符，则将其从链表中移走并返回给用户。如果该块太大，则将其分为两部分，尾部的部分分给用户，剩下的部分留在空闲链表中（更改头部信息）。因此`malloc`分配的是一块连续的内存。

4、释放时，首先搜索空闲链表，找到可以插入被释放块的合适位置。如果与被释放块相邻的任一边是一个空闲块，则将这两个块合为一个更大的块，以减少内存碎片。

****



**释放时，只给`free()`传了一个指针，怎么知道该释放多大？**

`malloc()`分配出来的空间会比原本申请的稍大一点，多出的这部分用于存放申请空间的大小`size`，这样在释放空间时才能知道该释放多少。



**如何避免频繁`malloc/free`生成大量内存碎片？**

内存池，在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。
（1）针对特殊情况，例如需要频繁分配释放固定大小的内存对象时，不需要复杂的分配算法和多线程保护。也不需要维护内存空闲表的额外开销，从而获得较高的性能。

（2）由于开辟一定数量的连续内存空间作为内存池块，因而一定程度上提高了程序局部性，提升了程序性能。

（3）比较容易控制页边界对齐和内存字节对齐，没有内存碎片的问题。

（4）当需要分配管理的内存在`100M`以下的时候，采用内存池会节省大量的时间，否则会耗费更多的时间。

（5）内存池可以防止更多的内存碎片的产生

（6）更方便于管理内存

系统层面：**Linux采用伙伴系统解决外部碎片的问题，采用slab解决内部碎片的问题。**

## 三. C++ 

### 1. **面向对象 vs 面向过程 **

**面向过程以步骤来划分问题**，偏向人类的思维习惯，分析出解决问题所需要的步骤，用函数将这些步骤一步步地实现，使用时一个个依次调用即可。

**面向对象是以功能来划分问题**，面向对象将构成问题事务分解为各个对象，建立对象的目的不是为了完成一个步骤，而是为了描述某个事物在整个解决问题的步骤中的**行为**。

对比：面向对象调用类时需要实例化，开销比较大，比较消耗资源，相较之下，面向过程的性能更好，单片机、嵌入式开发和Linux一般采用面向过程开发。但面向对象具有封装、继承和多态的特性，可以降低系统耦合度，更加灵活，更易维护。

- 面向对象的三大特性

  - 封装
  - 继承
  - 多态

- 继承特性的理解
  - 有的语言支持多继承，有的只支持单继承，单继承语言：C#，JAVA，PHP；多继承语言：C++
  - 继承不能改变父类的私有属性
  - 通过父类的public成员函数可以访问到父类的私有属性，但不能通过子类自己的成员函数访问到父类的私有属性。
  - 继承可以使子类具有父类的公共属性、方法以及保护属性、方法

#### 1.1 C语言实现面向对象

**前言**：面向对象编程（`OOP`）并不是一种特定的语言或者工具，它只是一种设计方法、设计思想，所以没必要太拘泥于编程语言。

- **封装**

  封装就是把数据和方法打包到一个类里面

  ```C++
  // Shape 的属性
  typedef struct {
      int16_t x; 
      int16_t y; 
  } Shape;
  
  // Shape 的操作函数，接口函数
  void Shape_ctor(Shape * const me, int16_t x, int16_t y);
  int16_t Shape_getX(Shape const * const me);
  ----------------------.h----------------------------
  Shape s1, s2;
  Shape_ctor(&s1, 0, 1);
  printf("Shape s1(x=%d,y=%d)\n", Shape_getX(&s1));
  ```

- **继承**

  继承就是基于现有的一个类去定义一个新类，这样有助于重用代码，更好的组织代码。

  在 `C` 语言里面，去实现单继承也非常简单，只要把基类放到继承类的第一个数据成员的位置就行了。

  ```C++
  // 矩形的属性
  // 结构体嵌套 -- 相当于 C++ 中的父子继承
  typedef struct {
      Shape super; // 继承 Shape
  
      // 自己的属性
      uint16_t width;
      uint16_t height;
  } Rectangle;
  
  // 构造函数
  void Rectangle_ctor(Rectangle * const me, int16_t x, int16_t y, uint16_t width, uint16_t height);
  -----------------------.h-----------------------
  
  // 构造函数
  void Rectangle_ctor(Rectangle * const me, int16_t x, int16_t y, uint16_t width,  uint16_t height)
  {
      /* first 调用父类构造函数 */
      Shape_ctor(&me->super, x, y);
  
      /* next, 初始化子类成员变量 */
      me->width = width;
      me->height = height;
  }
  
  // 析构函数： 先析构子类，再析构父类
  ```

- **多态**

  `C++ `语言实现多态就是使用虚函数。

  `C `语言里面，也可以实现多态；

#### 1.2 C++多态的作用

多态可以增强程序的可扩充性，原有程序需要修改/增加功能时只需改动/增加较少的代码。

具体做法是：抽象出多个类的共同特征（属性和方法）形成一个父类，在父类中实现好大致的程序框架，其中概括了这一类事物的共同特点。将其中因事物而异的具体动作定义为虚函数，具体实现延缓到各个子类去设计。如果要新增一个具有这些特征的事物类，所做的事情也只是从父类派生出一个新类，实现与其他子类不同的动作。

#### 1.3 C语言实现多态

- **`c++`中的虚表和虚指针**

  虚表（`Virtual Table`）是这个类所有虚函数的函数指针（函数入口）的集合，通过虚表实现对虚函数的寻址

  虚指针（`Virtual Pointer`）是一个指向虚表的指针。这个虚指针必须存在于每个对象实例中，会被所有子类继承

- **在构造函数中初始化虚函数指针指向虚函数表**

  在每一个对象实例中，`vptr` 必须被初始化指向其 `vtbl`。最好的初始化位置就是在类的构造函数中。事实上，**在构造函数中，`C++` 编译器隐式的创建了一个初始化的虚指针`vptr`，并为该指针赋值**。在 `C` 语言里面， 我们必须显示的初始化`vptr`。

  ```C++
  struct ShapeVtbl;
  // 父类 Shape 的属性
  typedef struct {
      struct ShapeVtbl const *vptr;	// 虚函数指针 —— 指向虚表
      int16_t x; 
      int16_t y; 
  } Shape;
  
  // 父类 Shape 的虚表 —— 虚函数指针集合
  struct ShapeVtbl {
      uint32_t (*area)(Shape const * const me); // 一个虚函数指针
      void (*draw)(Shape const * const me);
  };
  
  
  ---------------------新的构造函数------------------
  // 父类的构造函数
  void Shape_ctor(Shape * const me, int16_t x, int16_t y) 
  {
      // 父类 Shape 类的虚表
      static struct ShapeVtbl const vtbl = 
      { 
         &Shape_area_, // 父类的虚函数地址
         &Shape_draw_
      };
      me->vptr = &vtbl; // 初始化虚函数指针
      me->x = x;
      me->y = y;
  }
  
  // Shape 类的虚函数实现
  static uint32_t Shape_area_(Shape const * const me) 
  {
      assert(0); // 类似纯虚函数
      return 0U; // 避免警告
  }
  
  static void Shape_draw_(Shape const * const me) 
  {
      assert(0); // 纯虚函数不能被调用
  }
  ```

- **继承 `vtbl` 和 重载 `vptr`**

  **基类包含 `vptr`，子类会自动继承。但是，`vptr` 需要被子类的虚表重新赋值。并且，这也必须发生在子类的构造函数中。**

  ```C++
  // Rectangle 虚函数 —— 子类 override 虚函数
  static uint32_t Rectangle_area_(Shape const * const me);
  static vo   id Rectangle_draw_(Shape const * const me);
  
  // 子类构造函数
  void Rectangle_ctor(Rectangle * const me, int16_t x, int16_t y,uint16_t width, uint16_t height)
  {
      // 子类的虚表
      static struct ShapeVtbl const vtbl = 
      {
          &Rectangle_area_,  // 子类重写的虚函数地址
          &Rectangle_draw_
      };
      Shape_ctor(&me->super, x, y); // 调用基类的构造函数
      me->super.vptr = &vtbl;       // 重载 vptr
      me->width = width;
      me->height = height;
  }
  ```


### 2. 虚函数

#### 2.1 构造析构能否为虚？

构造函数不能是虚函数，析构函数可以是虚函数（父类的析构函数需定义为虚函数）。

（1）从存储空间角度上来看：如果构造函数是虚函数，就需要通过虚表来调用。而**虚表是存储在对象的内存空间**的，调用构造函数前对象还没有实例化出来，也就是内存空间还没有，无法找到虚表。所以，在构造出对象前是不能调用虚函数的。

​		 从使用角度上来看：虚函数的作用在于通过父类的指针动态地调用子类的成员函数，而构造函数是在创建对象时自动调用的，不可能通过父类的指针去调用，因此也就规定了构造函数不能是虚函数。

（2）析构函数可以是虚函数，且常常如此。

因为此时虚表已经初始化了，我们通常通过基类的指针来销毁对象，如果析构函数不是虚函数，就不能实现运行时期的动态绑定，只会在编译期间静态绑定，仅会调用父类的析构函数，不会调用子类的析构函数。当子类的析构函数中有释放堆区空间的操作时，如果父类的析构函数不是虚函数，就会导致内存泄漏。

#### 2.2 不能为虚函数的函数

虚函数是针对有继承特性的，且被子类override（覆盖）了的类成员函数而言的，因此普通函数和友元函数不能是虚函数。

- **不是类成员的普通函数**：只能重载，不能被覆盖，在编译时就绑定函数了。

- **友元函数**：不属于类的成员函数，不能被继承，对没有继承特性的函数没有虚函数的说法。

在有继承特性的类成员函数中，有以下几种函数不能为虚函数：

- **构造函数**：从存储空间的角度来看，构造函数调用前，对象都还没有产生，无法找到虚表（虚表中存放着对象拥有的虚函数的地址），也就无法调用虚函数。而且从使用的角度来讲，是无法通过父类的指针去调用子类的构造函数的。

- **内联成员函数**：内联函数在编译时就被展开了，而虚函数在运行时才能动态地绑定函数，不可能统一。我试过，虚函数声明为内联函数不会报错，可以正常地进行动态绑定，为什么呢？因为内联函数最终是否内联是由编译器决定的，遇到虚函数的情况编译器只会将其当作普通函数来处理，所以尽管将其声明为内联函数，但实际上它只是一个普通的虚函数而已。

- **静态成员函数**：所有对象共享一份代码，不归某个对象所有，没有动态绑定的必要。

### 3. 宏 模板 内联

|          |                   宏                   |                             模板                             |                           内联函数                           |
| :------: | :------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 处理时机 |               预编译时期               |                           编译时期                           |                           编译时期                           |
| 类型检查 | 无，仅单纯文本替换，无论对错，直接替换 |                       有，是类型安全的                       |                       有，是类型安全的                       |
| 代码产生 |              直接产生代码              | 只有当模板实例化后才会产生代码，实例化几种类型就要产生几份代码 | 只是给编译器建议，具体是否内联还看编译器，如果函数体积过大，编译器会自动将其变成普通函数 |
|   作用   |           节省函数调用的开销           |                           代码重用                           |                      节省函数调用的开销                      |

**内联函数的限制：**

- 函数中不可含有循环，switch 语句，否则编译器会将其变成普通函数

- 函数**不可为递归函数**，因为递归次数未知，如果内联就需要扩展代码，不知道到底要扩展多少次

- 函数**不可为虚函数**，因为虚表机制需要一个真正的函数地址，而内联函数开展以后不是一个函数，而是一段简单的代码

  ![image-20210830174223560](https://i.loli.net/2021/08/30/Tdo1Fa9ZKIhjCmb.png)

  ![image-20210830174257162](https://i.loli.net/2021/08/30/uzfZIGyCQnDcHE8.png)

  我试了以下，虚函数是内联函数时仍然能正确地动态绑定，为什么呢？

  原因是：**即使虚函数被声明为了内联函数，编译器遇到这种情况根本不会将这样的函数内联展开，而是当作普通函数来处理。**

**`inline`必须与函数定义体放在一起才能使函数成为自动地成为内联函数**。

**模板**本质上并非代码，而是指导编译器生成代码的指令，模板实例才是真正的程序代码。编译器看到模板定义时不会立刻生成代码，只有看到模板的使用时，才会进行实例化，用特定模板实例代码。

### 4. 指针 vs 数组



**指针数组与数组指针的区别：**

- 指针数组：本质是一个数组，数组元素是一个个的指针

  ```C++
  int *a[10];    // [] 的优先级比 * 高， 数组元素是 int* 类型的
  ```

- 数组指针：本质是一个指针，指向一个数组

  ```C++
  int (*p)[10];
  ```

### 5. 引用

#### 5.1 指针 vs 引用

指针也是变量，只不过它存放的数据是另一个变量所在的地址，也可以说**指针是一块内存的地址**。指针在逻辑上是独立的，可以让指针的指向，也可以改变其所指变量里面存放的数据。

引用是一个别名，在逻辑上不独立，==它的存在具有依附性，所以引用必须在一开始就被初始化==，而且就不能再和其他对象绑定在一起了（自始至终只能依附于同一个变量）。

**从编译的角度来看：**程序在编译时分别将指针和引用添加到符号表上，符号表上记录的是变量名称以及变量所对应的地址。指针变量在符号表上对应的地址值为存放指针变量的地址，而引用在符号表上对应的地址值为存放引用对象的地址。符号表生成后就不会再改，因此引用一旦绑定对象就不能更改。

**指针和引用常用于函数的参数传递，指针传递参数和引用传递参数有着本质的区别：**虽然它们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。而对于指针传递的参数，如果改变被调函数中的指针地址，它将影响不到主调函数的相关变量，只能使用指向指针的指针。

（在被调用函数中改变不了主调函数中的指针指向）

![image-20210827135541294](https://i.loli.net/2021/08/27/2ikufGgKDlt4Rjh.png)

（1）==指针是一个实体，而引用只是一个别名==

（2）引用“从一而终”，指针可以“见异思迁”，引用只能在定义时被初始化一次，之后不可变

（3）引用没有const，指针有const，const的指针不能改变指向

（4）引用不能为空，指针可以为空

<img src="https://i.loli.net/2021/08/27/1NLDgMuOXQtAGK8.png" alt="image-20210827144520094" style="zoom:80%;" />

#### 5.2 右值引用的作用

**（1）什么是左值和右值**

左值：本质上是存储在计算机内存中的对象。是变量，可以放在赋值符号的左边被修改，也可以放在右边给别的变量赋值（也即可读可写）。++ a

==右值：是对应变量的值本身，常量/表达式返回值/临时变量，只能读，不能被修改，不能取地址。不能做a ++等操作==

```C++
int a = 3;
const int b = 5;
a = b + 2;      // a 为左值，b + 2 为表达式返回值，为右值
b = a + 2;      // × b 是右值，不能出现在在赋值符号左边，不能被修改
(a = 4) += 28;  // a = 4 为左值表达式，28 为右值，+= 为赋值操作符
34 = a + 2;     // × 34 是字面量，不能做左值
```

**左值引用和右值引用**



**（2）右值引用的应用**

右值引用主要用于移动语义和完美转发。类的右值是一个临时对象，如果没有被绑定到引用，在表达式结束时就会被析构；可以搭配移动语义将实现资源所有权的移交，将一个即将被销毁的对象资源移交给另一个对象，可以避免一次析构和一次重新构造（重新构造意味着深拷贝）。

**对于左值，可以通过std::move()将其转换为右值引用，std::move()实际上是 static_cast<T&&>()的简单封装。**

假设现在有一个函数返回一个 String 类型的对象。

<img src="https://i.loli.net/2021/08/30/t91HCXTh8Jerqdm.png" alt="image-20210830022609303" style="zoom:80%;" />

代码上看没啥问题，但有一点不太好：`GetString`函数返回的临时对象，将 s2 拷贝构造成功后，立马就销毁了（临时对象的空间被释放），再没有其他作用；而 s2 在拷贝构造时，又需要分配空间，一个刚释放一个又申请，有点多此一举。能否直接将临时对象的空间交给 s2 ，省去销毁和重新开辟空间的步骤呢？

**将一个对象中资源移动到另一个对象中的方式，称为移动语义。而C++11中如果需要实现移动语义，必须使用右值引用。**

#### 5.3 移动构造  移动赋值

- **移动赋值**

  将一个对象的资源移动给另一个对象，并将该对象置空。（转移）

  为何要这么做？按照一般的拷贝构造，在返回一个临时对象时，会进行深拷贝，这里的临时对象是一个将亡值（生命周期即将结束的值），我们对其进行深拷贝是一种浪费资源和时间的行为，那我们利用这个移动构造，直接将将亡值的资源转移给新的对象中，减少了拷贝，提高了效率。

  ```C++
  // 移动拷贝
  String(String&& str) 
  	:m_data(nullptr)
  {
      swap(m_data, str.m_data);
  }
  ```

- **移动赋值**

  移动赋值也是为了减少拷贝。

  ```C++
  String& operator=(String&& str) {
  	swap(m_data, str.m_data);
      return *this;
  }
  ```

  **对于左值，可以通过std::move()将其转换为右值引用，std::move()实际上是 static_cast<T&&>()的简单封装。**

- **重载 += 运算符体现了左值引用**

  ```C++
  // 传参和返回值都使用了左值引用，因此没有调用构造函数生成临时对象，减少了拷贝
  String& operator+=(const String& str) {
      // this->Append(str.m_data);
      return *this;
  }
  ```

- **重载 + 运算符体现了右值引用**

  ```C++
  // s1 + s2 得到临时对象 tmp，自动调用移动构造和移动赋值以减少拷贝
  String operator+(const String& str) {
      String tmp(*this); 
      // this.Append(str.m_data);
      return tmp;
  }
  ```

#### 5.4 完美转发

完美转发是指在函数模板中，完全按照模板的参数类型，将参数传递给函数模板中调用的另外一个函数。简单而言，完美转发可以**保持数据的原有属性，原来是左值经过完美转发后还是左值，原来是右值完美转发还是右值。**

![image-20210830031639927](https://i.loli.net/2021/08/30/rJSR3BLhHVGq9uk.png)

完美转发涉及到引用折叠和模板推导。**通过引用折叠，实现了万能模板。在万能模板内部，利用 forward 函数，本质上又利用了一遍引用折叠，实现了完美转发。其中模板推导扮演了至关重要的角色。**

#### 5.5 引用折叠

引用折叠就是将左值引用和右值引用排列组合的规则，有四种情况：

```C++
// 任一引用为左值引用，则结果为左值引用；只有两个都为右值引用时，结果为右值引用
- 左值-左值 T& &   -》&
- 左值-右值 T& &&  -》&
- 右值-左值 T&& &  -》 &
- 右值-右值 T&& && -》 &&
```

`int & &a = b;`是不允许的噢，不允许使用引用的引用。那为啥还要有引用折叠的概念存在？因为引用折叠的应用场景不在这。引用折叠在模板中应用于完美转发。

#### 5.6 万能引用

万能引用并非 C++ 语法特性，而是利用现有的 C++ 语法，自己实现的一个功能。这个功能既能接收左值类型的参数，也能接受右值类型的参数，所以叫万能引用。也就是说，**模板中的 T 保存着传递进来的实参的信息。**

万能引用的形式：

```C++
template<typename T> 
ReturnType Function(T&& param) {
    
}
```

为什么这种函数能万能引用不同类型的参数？

因为 `&& = &&，&& & = &, && && = &&`

编译器不允许我们写类似 `int & &&`这样的代码，但是它自己可以推导出`int & &&`这样的代码出来。它的理由是：编译器虽然推导出 `T`为`int &`，但我在最终生成的代码中，利用引用折叠规则，将`int & &&`等价生成了`int &`。推导出来的`int & &&`只是过渡阶段，最终版本并不存在，所以就不算破坏规则。

#### 5.7 std::forward()

![image-20210830034011739](https://i.loli.net/2021/08/30/OQsLx1FXck7Umgw.png)

当外部传入参数给函数`PerfectForward()时，参数既可以被初始化为左值引用，也可以被初始化为右值引用，取决于传递的实参 t 的类型。但是当我们在函数内部，将实参 t 传递给另外一个函数 Fun 时，此时 t 是被当作左值进行传递的。**因为 t 只是个具名的对象，任何的函数内部，对形参的直接使用，都是按照左值进行的。**

万能引用内部形参都变成了左值，还如何万能引用？

用 std::forward 改变这种情况。`f(t)`改成`f(std::forward<T>(t))`强制类型转换 t 使得它和实参的类型一致。

**std::forward 是如何利用到 T 的信息的呢？**

它的源码形式大致是这样的：

```C++
template<typename T>
T && forward(T &param) {  // T& 经过引用折叠都是左值引用类型
    return static_cats<T&&>(param);// 强制类型转换 & && = &，&& && = &&
}
```

又进行了一遍模板推导。

#### 5.8 String 类 

STL 中的 string 类，里面有一个 char 类型的指针，构造函数中需要为其动态分配内存，涉及到这种资源管理，用户必须显式地提供三大函数——拷贝构造、拷贝赋值和析构函数。

```C++
class String {
public:
    // 构造函数
    String(const char* cstr = 0) {
        if (cstr) {
            m_data = new char[strlen(cstr) + 1]; // +1 是因为字符串结束符 \0
            strcpy(m_data, cstr);
        }
        else { // 未指定初值
            m_data = new char[1];
            *m_data = '\0';
        }
    }
    
    // 拷贝构造 s-左值对象 拷贝是深拷贝，要重新开辟内存
    String(const String& str) 
    	: m_data(new char[strlen(str.m_data) + 1]) 
    {
        strcpy(m_data, str.m_data); // 因为兄弟之间互为 friend，所以可以直接取对方的 private data
    }
    
    // 拷贝赋值 
    String& operator=(const String& str) {
        // 注意一定要先检测是否为自己给自己赋值
        // 如果指向的是同一块内存区域，释放了 m_data 就找不到 str.m_data 了
        if (this == &str) {  // self assignment
            return *this;  
        }
        
        // 三步：释放原有的内存，申请新的内存，填入内容
        delete[] m_data;
        m_data = new char[strlen(str.m_data) + 1];
        strcpy(m_data, str.m_data);
        
        return *this; // this 是当前对象的地址，*this 是当前对象本体
    }
    
    // 析构函数
    ~String() {
        if (m_data) delete[] m_data;
    }
    
    char* get_c_str() const {
        return m_data;
    }
    
private:
    char* m_data;
}

// 重载 << 
ostream& operator<<(ostream& os, const String& str) {
    os << str.get_c_str();
    return os;
};
```

**为什么一定要自定义拷贝构造和拷贝赋值函数？**

如果不定义，就会调用默认拷贝构造/默认拷贝赋值函数的后果如下：浅拷贝，不会为被赋值的String 对象中的 m_data 重新分配内存，只是让该指针指向拷贝的那块内存区域而已。因此要自定义来实现深拷贝。

<img src="https://i.loli.net/2021/08/30/So4nZLu9YJIwRW3.png" alt="image-20210830014732136" style="zoom:67%;" />

**为什么拷贝赋值函数中一定要检测自我赋值？**

因为拷贝赋值分为三个步骤，分别是释放旧的内存空间，申请新的内存空间，填入新的内容。如果是自我赋值（赋值的和被赋值的是同一块内存区域），但没有进行检测的话，首先会直接将内存空间释放掉，最后会访问赋值的那块内存空间，而这块空间已经被释放掉了，此时就产生了不确定行为。

<img src="https://i.loli.net/2021/08/30/UW87jnLQHv2F3dZ.png" alt="image-20210830020314976" style="zoom:67%;" />

### 5. 类的内存占用

- 空类大小：1字节
- 包含`1 ~ N`个虚函数的类大小：会有一个虚函数指针指向虚表，指针占`4/8 字节`

- 有继承的虚函数类大小：继承基类的虚函数指针，如果继承了m个类，n个父类有虚函数，那子类就有n个虚指针

### 6. 智能指针

#### 6.1 存在意义

- **什么是智能指针？**

  在智能指针中，一个对象什么时候析构是由智能指针本身决定的，不需要用户管理。

  - 从浅层来看，智能指针是利用了 `RAII` 机制是对普通指针进行了封装
  - **实质上，智能指针是一个对象，只是它的行为表现得像是一个指针**
  - 建立了所有权的概念，以及引用计数机制
  - 头文件：<memory>
  - `STL` 提供了四种：`auto_ptr`、`unique_ptr`、`shared_ptr`、`weak_ptr`

- **智能指针的意义是什么？**

  智能指针主要是为了避免**内存泄漏**。普通指针如果指向某个对象，使用完后需要用户自行释放它，若没有释放就会造成内存泄漏。有以下两种情况：（1）用户忘记释放；（2）异常安全问题：即使代码中写入了`delete`关键字，但不是在适当的地方（抛出异常前），如果程序发生异常，可能就执行不到`delete`那行代码。

  为了避免这些问题，就出现了智能指针，用户就不用管内存的释放问题了。

- **智能指针哪里智能？**

  ```C++
  int* p1 = new int(1);
  int* p2 = p1;
  ...
  delete;
  delete;
  // 出错
  ```

  当两个指针指向同一个对象时，程序会两次删除该对象，这是不能接受的。要避免，有以下方法：

  - **×** 重载拷贝赋值函数，进行深拷贝，让两个指针指向不同的对象，其中一个对象是另外一个对象的副本，缺点是浪费空间，所以智能指针都没有采用此方案

  - **√** 建立所有权的概念，对于特定的对象，只能有一个智能指针可拥有，解决了所指对象被多次`delete`的问题 ，`auto_ptr`和`unique_ptr`采用了这种策略，后者的策略更加严格
  - **√** 跟踪引用特定对象的智能指针数，也就是引用计数机制。赋值时，计数 + 1，指针过期时，计数 - 1，当减为 0 所有指针都失效时才调用 `delete`，不会多次删除一个对象，这是`shared_ptr`采用的策略

#### 6.2 `auto_ptr`和`unique_ptr`

- **为何摒弃`auto_ptr`？**

  （1）优点：所有权互斥，可以保证同一时刻只允许一个指针指向给定的对象，避免同一对象被多次删除）

  （2）缺点：`auto_ptr` 进行赋值操作时，去赋值的一方将其所有权转让给被赋值的一方，去赋值的一方就丧失使用权了，空指针是无法使用的。摒弃它是为了**避免潜在的内存崩溃问题**。无移动语义。

- **`为何 unique_ptr`优于 `auto_ptr`?**

  首先它俩的相同之处在于：对持有的资源都具有独占性，杜绝了同一对象被多次删除的可能性，不同之处在于：

  （1）**更加安全**

  `auto_ptr`可以赋值（其实是转让），而`unique_ptr`**禁止拷贝**，不能拷贝赋值（拷贝构造和拷贝赋值都 `delete` 掉了），从而避免了前面所说的转让一方指针被剥夺所有权后，不再指向有效数据的问题，所以`unique_ptr`更加安全。实在想转移所有权的话，使用移动语义，比如：`ptr1 = std::move(ptr)`，它可以将`ptr`的所有权交给`ptr1`，并将`ptr`变成空指针。

  （2）**更加聪明**

  `unique_ptr`可以将一个智能指针赋给另一个并不会留下危险的悬挂指针。

  函数返回的临时`unique_ptr`可以由一个`unique_ptr`来接管，因为返回时临时的 `unique_ptr` 就被销毁了，根本没机会使用它 来访问无效的数据。编译器允许这种赋值，这正是`unique_ptr`更聪明的地方。**当程序试图将一个` unique_ptr` 赋值给另一个时，如果源 `unique_ptr` 是个临时右值，编译器允许这么做；如果源 `unique_ptr` 将存在一段时间，编译器将禁止这么做**。

#### 6.3 `unique_ptr`

- **初始化方式**

  ```C++
  //初始化方式1
  std::unique_ptr<int> sp1(new int(123));
  
  //初始化方式2
  std::unique_ptr<int> sp2;
  sp2.reset(new int(123));
  
  //初始化方式3
  std::unique_ptr<int> sp3 = std::make_unique<int>(123);   // √ 建议使用，更加安全
  ```

- **禁止复制**

  鉴于 **`std::auto_ptr`** 的前车之鉴，**`std::unique_ptr`** 禁止复制语义，为了达到这个效果，**`std::unique_ptr`** 类的拷贝构造函数和赋值运算符（`operator =`）被标记为 **`delete`**。

  ```C++
  template <class T>
  class unique_ptr
  {
      ...
      //拷贝构造函数和赋值运算符被标记为 delete
      unique_ptr(const unique_ptr&) = delete;
      unique_ptr& operator=(const unique_ptr&) = delete;
  };
  ```

  因此，下列代码是无法通过编译的：

  ```C++
  std::unique_ptr<int> sp1(std::make_unique<int>(123));;
  
  std::unique_ptr<int> sp2(sp1);  // ×  无法使用拷贝构造
  
  std::unique_ptr<int> sp3;
  
  sp3 = sp1;                      // ×  无法使用拷贝赋值
  ```

- **允许复制的特例**

  禁止复制语义也存在特例，即可以通过一个函数返回一个 `unique_ptr`，它是临时的，可以给其他`unique_ptr`赋值：

  ```C++
  #include <memory>
  
  std::unique_ptr<int> func(int val)
  {
      std::unique_ptr<int> up(new int(val));
      return up;
  }
  
  int main()
  {
      std::unique_ptr<int> sp1 = func(123);
  
      return 0;
  }
  ```

- **移动构造**

  既然 **`std::unique_ptr`** 不能复制，那么如何将一个 **`std::unique_ptr`** 对象持有的堆内存转移给另外一个呢？答案是使用移动构造，示例代码如下：

  ```C++
  #include <memory>
  
  int main()
  {
      std::unique_ptr<int> sp1(std::make_unique<int>(123));
  
      std::unique_ptr<int> sp2(std::move(sp1));
  
      std::unique_ptr<int> sp3;
      sp3 = std::move(sp2);
  
      return 0;
  }
  ```

  利用 `std::move` 将 `sp1` 持有的堆内存（值为 `123`）转移给 `sp2`，再把 `sp2 `转移给 `sp3`。最后，`sp1` 和 `sp2` 不再持有堆内存的引用，变成一个空的智能指针对象。并不是所有的对象的 `std::move` 操作都有意义，只有实现了移动构造函数（Move Constructor）或移动赋值运算符（`operator =`）的类才行，而 **`std::unique_ptr`** 正好实现了这二者，以下是实现伪码：

  ```text
  template<typename T, typename Deletor>
  class unique_ptr
  {
      //其他函数省略...
  public:
      unique_ptr(unique_ptr&& rhs)
      {
          this->m_pT = rhs.m_pT;
          //源对象释放
          rhs.m_pT = nullptr;
      }
  
      unique_ptr& operator=(unique_ptr&& rhs)
      {
          this->m_pT = rhs.m_pT;
          //源对象释放
          rhs.m_pT = nullptr;
          return *this;
      }
  
  private:
      T*    m_pT;
  };
  ```

- **一组堆对象**

  **`std::unique_ptr`** 不仅可以持有一个堆对象，也可以持有一组堆对象，示例如下：

  ```text
  #include <iostream>
  #include <memory>
  
  int main()
  {
      //创建10个int类型的堆对象
      //形式1
      std::unique_ptr<int[]> sp1(new int[10]);
  
      //形式2
      std::unique_ptr<int[]> sp2;
      sp2.reset(new int[10]);
      //形式3
      std::unique_ptr<int[]> sp3(std::make_unique<int[]>(10));
  
      for (int i = 0; i < 10; ++i)
      {
          sp1[i] = i;
          sp2[i] = i;
          sp3[i] = i;
      }
  
      for (int i = 0; i < 10; ++i)
      {
          std::cout << sp1[i] << ", " << sp2[i] << ", " << sp3[i] << std::endl;
      }
  
      return 0;
  }
  ```

#### 6.4 `shared_ptr`

持有的资源可以在多个`shared_ptr`之间共享，`shared_ptr`提供了一个`use_count()`方法来获取当前持有资源的引用计数。（1）每多一个`shared_ptr`对资源的引用，资源引用计数将增加1；（2）每一个指向该资源的`shared_ptr`对象析构时，资源引用计数就减1；（3）最后一个`shared_ptr`对象析构时，资源引用计数为0，将释放其持有的资源。多个线程之间，递增和减少资源的引用计数是安全的。

- **初始化方式**

  ```text
  //初始化方式1
  std::shared_ptr<int> sp1(new int(123));
  
  //初始化方式2
  std::shared_ptr<int> sp2;
  sp2.reset(new int(123));
  
  //初始化方式3
  std::shared_ptr<int> sp3;
  sp3 = std::make_shared<int>(123);
  ```

- **循环引用问题**

  ```C++
  class B;
  
  class A
  {
  public:
  	shared_ptr<B> pb;
  };
  
  class B
  {
  public:
  	shared_ptr<A> pa;
  };
  
  int main()
  {
  	shared_ptr<A> pa(new A);
  	shared_ptr<B> pb(new B);
  	pa->pb = pb;
  	pb->pa = pa;
  	return 0;
  }
  ```

  有两个类 A 和 B，A 类中有 B 对象的`shared_ptr`成员变量，B 类中也有 A 对象的`shared_ptr`成员变量。使用时，分别创建 A 对象和 B 对象的`shared_ptr`，且 A 对象的`shared_ptr`成员变量引用 B 对象，B 对象的`shared_ptr`成员变量引用 A 对象。

  对于嵌套类来说，析构顺序是由内到外。如果要析构 A 对象，首先要析构其成员变量—— B 对象，等析构完 B 对象后才能去析构 A 对象。但是，如果要析构 B 对象，首先要析构其成员变量—— A 对象，等析构完 A 对象后才能去析构 B 对象。如此一来就陷入了死循环，A 对象和 B 对象都不能得以析构。

  循环引用问题怎么解决？

  （1）手动打破，在使用完之后，手动释放一个对象。如`pa->pb.reset();`

  （2）配合`weak_ptr`使用。

#### 6.5 `weak_ptr`

`weak_ptr` 是专门用来帮助` shared_ptr`解决循环引用问题而引入的。使用时，用一个创建好的`shared_ptr`对象来初始化`weak_ptr`对象，`weak_ptr`是弱引用，它的创建不会影响`shared_ptr`的引用计数。

使用`weak_ptr`对象之前需要调用`expired`函数来判断引用的资源是否过期。如果没有过期，才能进行操作（调用`rock`函数来获取`share_ptr`对象）。

调用`reset()`将`weak_ptr`对象置空。

#### 6.6 使用选择

当你不确定使用的指针是不是被分享所有权的时候，默认选 `unique_ptr` 独占式所有权，因为 `unique_ptr` 效率比 `shared_ptr `高，不需要维护引用计数和背后的控制块。当确定要被分享的时候可以转换成 `shared_ptr`。

另外其实不是说两个指针分享同一个变量就需要用 `shared_ptr`，尤其是不涉及到多线程的程序中，不使用智能指针也没关系。

有必要使用 `shared_ptr` 的场景举例：

```C++
----------------------------------------
|               Thread 1               |
| ------------------------------------ |
| void func(shared_ptr<int> p) { ... } |
----------------------------------------

-------------------------------------------
|              Main Thread                |
| --------------------------------------- |
| shared_ptr<int> p = make_shared<int>(); |
| func(p);                                |
-------------------------------------------
```

### 7. lambda 表达式

是匿名函数还是匿名类

如果引用捕获的值被释放掉怎么处理

### 8. `explict`

- #### 为何尽量使用 `explict` 关键字？

  使用`explicit`可以禁止编译器自动调用拷贝初始化，还可以禁止编译器对构造函数的参数进行隐式转换。在`c++`中`explicit`关键字只能用来修饰**构造函数**。

- #### 什么是拷贝初始化？

  ![image-20210901011550551](https://i.loli.net/2021/09/01/RbyaLEik2fjezpX.png)

  ![image-20210901011609681](https://i.loli.net/2021/09/01/w8BtHkTWaZoezlu.png)

  

  如果不希望这样，就要在构造函数前面加上`explicit`关键词禁止编译器进行这种自动调用拷贝初始化的行为。

  

  ![image-20210901011826571](https://i.loli.net/2021/09/01/unBE7wMIoqYrpRL.png)

  

- #### 什么是编译器会对构造函数的参数进行隐式转换？

  ![image-20210901012258495](https://i.loli.net/2021/09/01/yLlknuMsrB5iaZe.png)

### 9. 类型转换

### 10. 在堆/栈上实例化对象

如何定义一个只能在堆上（栈上）实例化对象的类？

- **只能在堆上实例化**   A *pa = new A;

  栈上对象的生命周期是由编译器来管理的，首先由编译器分配内存空间；然后调用构造函数来构造栈对象；对象使用完后，调用析构函数来释放栈对象所占用的空间。在为类对象分配栈空间前，编译器都会检查该类的析构函数的访问性，如果不可访问，就不会在栈上实例化对象（因为它知道后面无法释放）。只要将析构函数私有化（private）就可以防止在栈上实例化对象。但这样的话 delete 的时候也无法调用析构函数，而且无法解决继承的问题，如果它作为其他类的基类，析构函数通常要被设为虚函数，然后在子类中重写以实现多态，因此析构函数不能设为私有的。

  为了解决继承的问题，将析构函数的控制权限设置为 protected，类外无法访问，但子类可以访问。

  为了解决堆上对象的释放问题，在类内定义一个 public 的成员函数，用于释放内存和析构对象，如果要统一，可以也定义一个成员函数用于申请内存和构造对象。也就是说将 new 和 delete 都封装成 public 的成员函数，前者必须是静态的。

  ```C++
  class A
  {
  protected:
      A() {}
      ~A() {}
  public:
      static A* create() { return new A(); }  // 静态成员函数，构造对象前就能调用
      void destroy() { delete this; }         // 类内成员函数，可以调用 protected 权限的析构函数
  };
  ```

- **只能在栈上实例化**   A a;

  也即不能通过new来实例化对象，new一个对象主要包括两个环节：（1）分配内存（调用 operator new() 函数）；（2）调用构造函数构造对象，初始化分配的内存空间。破坏任何一个环节都可以阻止在堆上实例化对象。

  - 只要将 operator new 在类内重载为私有的，第一步就无法完成

    ```C++
    class A 
    {
    private:
        void* operator new(size_t t) {}      // 注意函数的第一个参数和返回值都是固定的
        void operator delete(void* ptr) {}   // 重载了 new 就需要重载 delete
    public:
        A() {}
        ~A() {}
    };
    ```

  - 只要将构造函数私有化，new就调用不到构造函数，第二步就无法完成

    那要在栈上实例化对象怎么办？

    用单例模式的思想产生对象即可。定义一个私有的静态成员属性——类的对象（static A a;），静态成员函数，类内成员是可以访问私有成员的，静态成员函数中调用构造函数在栈上实例化一个对象出来并返回该对象。

    ```C++
    class A 
    {
    private:
        static A a;
        A() {}
        
    public:
        static A getA() { return a; }
        ~A() {}
    };
    ```


### 11. C 与 C++的区别

- **C 语言是面向过程的语言，C++ 是面向对象的语言。**

  （1）面向过程编程：将问题分解为一个个步骤，使用时一个个依次调用。

  （2）面向对象编程：将问题分解为各个对象，对象用以描述某个事物的行为。

  面向过程的性能更高，面向对象需要实例化对象，开销大，但面向对象可以降低系统的耦合，更加易于维护、复用和扩展。

- **关键字的差异**
  （1）`struct`：在 C 语言中 `struct` 定义的变量中不能有函数，而在 C++ 中可以有函数。
  （2）`malloc` ：`malloc` 函数的返回值为 `void*`，在 C 语言中可以赋值给任意类型的指针，在C++ 中必须强制类型转换，否则报错。
  （3）`struct`和`class`：class 是对 `struc`t 的扩展，`struct`默认的访问权限是`public`，而class默认的访问权限是`private`。

- **函数默认返回值**

  C语言支持默认 int，C++ 不支持，不能缺省函数返回值。

- **函数参数列表**

  在C语言中，函数没有指定参数列表时，默认可以接收任意多个参数；但在C++中，因为严格的参数类型检测，没有参数列表的函数，默认为 void，不接收任何参数。

  缺省参数是声明或定义函数时为函数的参数指定一个默认值。在调用该函数时，如果没有指定实参则采用该默认值，否则使用指定的参。（C语言不支持缺省参数）

- **函数重载**

  C语言没有函数重载，C++支持函数重载。

### 12. 定义 vs 声明

- **定义：只能出现在一个地方**，创建新对象，同时确定对象的**类型**并**分配内存**。
- **声明：可以出现多次**，描述对象的类型，用于指代其他地方定义的对象。它所说明的并非本身，extern 对象声明告诉编译器对象的类型和名字，对象的内存分配则在别处进行，由于并未在声明中为数组分配内存，所以并不需要提供关于数组长度的信息。

### 13. sizeof 和 strlen

sizeof 是实际分配的空间大小，不管是否填满

strlen 是计算字符串的长度，以 '\0' 为字符串结束标志，返回的长度不算结束标志。在 <cstring> 中

```C++
int strlen(const char* str) 
{
    assert(str != NULL);
    int len = 0;
    while ((*str++) != '\0') len ++;   // 不算 '\0'
    return len;
}
```

```c++
char a[] = "hello";
int b[] = {1, 2, 3, 4, 5};

cout << sizeof(a) << endl;              // 6 (字符串最后有一个'\0'标识字符串的结束)
cout << sizeof(b) << endl;              // 20
cout << sizeof(b)/sizeof(int) << endl;  // 5 获取数组元素个数

char c[10] = "hello";
int d[7] = {1, 2, 3, 4, 5};

cout << sizeof(c) << endl;   // 10 实际分配大小
cout << strlen(c) << endl;   // 5  字符串长度（探测到\0就知道字符串结束了）
cout << sizeof(d) << endl;   // 28 实际分配大小

char a[5] = "hello";         // ❌，放不下，因为还有一个'\0'
char a[6] = "hello";         // √
char a[] = "hello";          // √

char *p = "hello\n\0\n";
cout << strlen(p);           // 6
cout << sizeof(p);           // 8
```

### 14. 数组

```C++
int a[2][] = {1, 2, 3, 4, 5, 6};  // ❌ 只有第一维能省略，其他维都不能省略

int a[][2] = {1, 2, 3, 4, 5, 6};
for (int i = 0; i < sizeof(a)/sizeof(a[0]); i ++) {
    for (int j = 0; j < sizeof(a[0])/sizeof(int); j ++) {
        cout << a[i][j] << "   ";
    }
    cout << endl;
}
// 1   2   
// 3   4   
// 5   6  


// 数组定义的比较大，不够的空位的填0
int b[2][5] = {1, 2, 3, 4, 5, 6};
// 1   2   3   4   5   
// 6   0   0   0   0  


int c[][4] = {{1}, {2, 3}, {4, 5, 6}, {7, 8, 9, 10}};
// 1   0   0   0   
// 2   3   0   0   
// 4   5   6   0   
// 7   8   9   10   
// 内层每个{}表示对每一行进行赋值，内层有4个{}，因此有4行。
// 用{1}对第一行赋值，不够的空位填0，用{2，3}对第二行赋值...

int p;
int buf[10] = {1, 2, 3, 4, 5, 6, 9, 8};
p = (buf + 4)[2];   // buf + 4 是 buf[4] 的地址，[2] 表示再偏移 2 个元素的位置
cout << p;

// 指针数组，本质是一个数组，包含10个整型指针元素的数组
int *a[10];

int a[3] = {1, 2, 3};
// 数组指针，本质是一个指针，指向长度为2的整型数组
int (*p)[3] = &a;  // 不能写成 int (*p)[3] = a; 
p ++;              // 指针的步长为数组的长度（int * 3）

int b[3] = {1, 2, 3};
int (*q)[3] = &b;
for (int i = 0; i < 3; i ++) cout << *(q[0] + i) << " ";  // 1 2 3，这里的步长是一个数组元素

int a[2][3] = {1, 2, 3, 4, 5, 6};
int (*p)[3] = &a[0];
for (int i = 0; i < 3; i ++) cout << *(p[0] + i) << " ";   // 1 2 3
cout << endl;
for (int i = 0; i < 3; i ++) cout << *(p[1] + i) << " ";   // 4 5 6
cout << endl;
p ++;            // 步长为 3 个 int 的长度
for (int i = 0; i < 3; i ++) cout << *(p[0] + i) << " ";   // 4 5 6
cout << endl;
for (int i = 0; i < 3; i ++) cout << *(p[1] + i) << " ";   // 0 0 0
```

### 15. 字符串

```C++
char *p = "hello";      // "hello"是常量，放在静态区，指针 p 为局部变量，放在栈内，存了首字母的地址
char *q = "hello";
cout << p << endl;      // hello
cout << *p << endl;     // h
cout << *p+1 << endl;   // 105 -- h的ASCII码+1
cout << *(p+1) << endl; // e

char a[] = "hello";     // "hello"也是常量，放在静态区，拷贝一份给存放在栈中的局部变量--字符串数组a
char b[] = "hello";
cout << a << endl;      // hello
cout << &a[1] << endl;  // ello
cout << a+1 << endl;    // ello

cout << (p == q) << endl; // 1 p和q为指针，指向相同的常量区域（"hello"被存储在全局的静态区）
cout << (p == a) << endl; // 0
cout << (a == b) << endl; // 0 a和b为字符数组，是局部变量，各自存储在栈区

char x[] = "hello";                    // 会在后面追加字符结束符 \0
char y[] = {'h', 'e', 'l', 'l', 'o'};  // 不会在后面追加字符结束符 \0
char z[] = {'h', 'e', 'l', 'l', 'o', 0};
cout << sizeof(x) << endl;    // 6
cout << sizeof (y) << endl;   // 5
cout << sizeof (z) << endl;   // 6
```

```C++
char* func1() {
    char* p = "hello";        // "hello" 存在字符串常量区
    return p;                 // 返回字符串常量的地址，函数退出时所在内存不会被回收
}

char* func2() {
    char p[] = "hello";       // 字符串在内存中有两份拷贝，一份在栈中，一份在静态区
    return p;                 // 返回局部变量的地址，函数退出时栈会被清空
}

char* func3() {
    static char p[] = "hello"; // 如果函数非要返回一个局部变量的地址，局部变量必须声明为static类型
    return p;
}

int main() {
    char* str1 = func1();
    cout << str1 << endl;     // hello
    
    char* str2 = func2();     // ❌ 得到一个已经被释放的内存地址
    cout << str2 << endl;     // 打印出来是一个乱码
    
    char* str3 = func3();
    cout << str3 << endl;     // hello
}
```

#### memcpy   strcpy

```C++
char *strcpy(char* strDest, const char* strSrc)     // 源字符串只有可读权限，避免程序中被修改
{
    assert((strDest != NULL) && (strSrc != NULL));  
    char *address = strDest;                        // 复制前先保存目的字符串的首地址，最后要返回
    while ((*strDest++ = *strSrc++) != '\0');       // '\0' 也复制
    return address;                                 // 返回 char* 是为了使函数能支持链式表达式
}
// !!! strcpy 存在隐患，当源字符串长度超过目标字符串时，会导致数据写入我们无法控制的地址去
// 因此有了 strncpy，可以复制字符串的一部分到目的字符数组中
char *strcpy(char* strDest, const char* strSrc, size_t n) 
{
    assert((strDest != NULL) && (strSrc != NULL));
    char* address = strDest;
    while (n -- && (*strDest++ = *strSrc++) != '\0');
    return address;
}
```

```C++
void memcpy(void *dest, const void *src, size_t n)
{
    if (dest == NULL || src == NULL) return NULL;
    
    // 因为要按照一个字节拷贝，所以要将转换为 char* 类型来操作，指针 +1 就向前移动一个字节
    char *pDest = static_cast<char*>(dest);
    const char *pSrc = static_cast<const char*>(src);
    
    if (pDest > pSrc && pDest < pSrc + n)      // 存在重叠，目的内存首地址在源内存的中间
    {
        for (size_t i = n - 1; i != -1; -- i)  // 从后往前拷贝，以免在复制后半段前源字符串被覆盖了
        {
            pDest[i] = pSrc[i];
        }
    }
    else                                       // 没有重叠的情况
    {
        for (size_t i = 0; i != n; i ++)       // 从前往后拷贝
        {
            pDest[i] = pSrc[i];
        }
    }
    
    return dest;
}
```

memcpy 实现的注意点：

- 同样的，在函数入口处要检查源字符串指针和目标字符串指针是否有为空的，否则会产生不可预料的错误；
- 因为是按照一个字节拷贝，那就要把形参转换成`char*`类型来操作；（如果要按照 4 个字节来拷贝，将指针类型转换为 int* 来拷贝，但此时就无法避免覆盖的情况了）
- 要检查源内存和目标内存是否存在内存重叠，如果目标内存首地址在源内存的中间，则要从后往前拷贝，因为如果从前往后拷贝，那从目标内存首地址开始的地方就会被覆盖掉，如果没有重叠，或者源内存地址在目标内存的中间，那没有关系，可以从前往后拷贝；
- 不能使用`'\0'`来判断拷贝的结束，因为它是对一整块内存的拷贝，举一个浅显的例子，假设拷贝一个结构体，类似上面代码，那么它很可能拷贝到中间的某个地方就停止了，这个拷贝就相当于没有完成；
- 同样的，memcpy 也要返回目标字符串地址；

**区别**

- 复制的内容不同。

  strcpy 只能复制字符串，而 memcpy 可以复制任意内容，例如字符数组、整型、结构体、类等。

- 复制的方法不同。

  strcpy 不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，所以容易溢出。memcpy 则是根据其第3个参数决定复制的长度。

```C++
char str[13] = {0};
memcpy(str, "Hello-Ruijie", 5);   // Hello
cout << str << endl;

strcpy(str, "Hello-Ruijie");     // Hello-Ruijie
cout << str << endl;

memcpy(str, "wulawulawula", 9);  // wulawulawjie
cout << str << endl;

char* a = "AbCdEf", * b = "aB";
a ++;
b ++;
cout << strcmp(a, b);               // 正数
```

#### strcat strcpy strcmp

strcat（字符数组1，字符数组2），作用是连接两个字符数组中的字符串，将字符串2接到字符串1的后面，结果放在字符数组1中，函数返回字符数组1的地址。

```C++
char *strcat(char *dest, const char *src) // 将 src 拼接到 dest 后面
{
    assert(dest != NULL && src != NULL);
    char *ret = dest;       // 记下字符串的起始地址
    while (*dest != NULL) dest++;  // 指针 dest 移到字符串末尾的后面一个位置
    while ((*dest = *src))  // 将 src 中的字符逐个拷贝至 dest 后面，直到碰到 src 中的结束标志 \0 
    {
        src++;
        dest++;
    }
    return ret;
}
```

strcpy（字符数组1， 字符串2），作用是将字符串2复制到字符数字1中去。**字符数组1必须定义得足够大，不小于字符串2的长度**，以便能够容纳被复制的字符串。字符数组1必须携程数组名形式，字符串2可以是字符数组名，也可以是一个字符串常量。**复制时连同字符串后面的'\0'一起复制到字符数组1中。**可以用 strncpy（str1, st2, n）将 str2 中前面 n 个字符复制到 str1中去，然后再加一个 ‘\0'。

```C++
char *strcpy(char *dest, const char *src) 
{
    assert((dest != NULL) && (src != NULL));
    char *t = dest;
    while (*dest++ = *src++);       // 复制到 \0 时停止
    
    return t;
}
```

strcmp（字符串1，字符串2），作用是比较字符串1和2。
(1)  如果字符串1=字符串2，函数值为0。
(2)  如果字符串1>字符串2，函数值为一正整数。
(3)  如果字符串1<字符串2，函数值为一负整数

```C++
int strcmp(const char *str1, const char *str2) 
{
   if (strlen(str1) == strlen(str2))                      // 长度相等的话，逐个比较字符
   {
       while ((*dest != '\0') && (*src != '\0'))
       {
           if (*dest < *src) return -1;                  // 一旦碰到不同的字符，就不必再比较
           else if (*dest > *src) return 1;
           else ++dest, ++src;                           // 字符相同，比较下一个字符
       }
   }
   else return (strlen(str1) > strlen(str2) ? 1 : -1);   // 长度不等的话，直接根据长度判断大小
}
```



### 16. 多继承

```C++
class A 
{public:
    A() { cout << "构造A" << endl; }
    ~A() { cout << "析构A" << endl; }
};

class B: public A
{public:
    B() { cout << "构造B" << endl; }
    ~B() { cout << "析构B" << endl; }
};

class C: public B
{public:
    C() { cout << "构造C" << endl; }
    ~C() { cout << "析构C" << endl; }
};

int main()
{
    C c;
    cout << endl;
}

// 构造从最内层开始，析构从最外层开始
// 构造A
// 构造B
// 构造C

// 析构C
// 析构B
// 析构A
```

### 17. static

（1）static 修饰类成员数据：表示该数据属于整个类，实例化对象之前就可以访问。禁止在类内初始化（如果在类内初始化，会导致每个对象都包含该静态成员，所以不允许），类外初始化时不必再加 static 关键字（类外函数加 static 表示限定函数的作用域仅限本文件）

（2）修饰类成员函数： 该函数在实例化对象前就能访问，函数内不能访问非静态的成员数据和调用非静态的成员函数

（3）修饰局部变量：延长局部变量的声明周期，直到程序运行结束以后才释放、

（4）修饰全局变量：限定该变量只能在本文件中访问，即便是extern外部声明也不可以在其他文件中访问

（5）修饰函数：限定该函数只能在本文件中调用，不能被其他文件调用

### 18. const

（1）修饰普通变量，创建时必须初始化，限定变量不可修改（一旦创建就不能再修改）。）

```C++
int a = 2, b = 3;
const int *p = &a;   // const int 修饰（*p），*p 只可读不可写
*p = 3;              // × *p 不可写，不能通过指针 p 修改变量 a 的值
a = 3;               // √ 可以通过其他途径修改变量 a 的值
p = &b;              // √ 指针 p 可以改变指向

int a = 2, b = 3;    
int * const p = &a;  // const 修饰 p，p 只可读不可写
p = &b;              // × p 不可写，指针 p 不能改变指向
*p = 3;              // √ *p 可写，可以通过指针 p 修改变量 a 的值

const int a = 2;
const int &r = a;    // 对常量的引用
int &r1 = a;         // ×
```

（2）修饰函数的参数，保护实参，可以防止传入的参数的内容在函数内被修改，只对指针和引用有意义，如果是值传递，传给参数的仅仅是实参的副本，即使在函数体内改变了形参，实参也不会得到影响。

（3）修饰函数返回值，常用于运算符重载，使函数调用表达式不能作为左值。

（4）放在类的成员函数后面，修饰类的成员函数，限定在该函数内不能修改对象的数据成员，并且不能调用非 const 函数（因为非 const 函数可能修改数据成员，而 const 成员函数是不能修改数据成员的，所以在 const 函数中只能调用 const 函数）。静态函数没有this指针，不能定义为虚函数。



### 19. 字节对齐

- 为了使 CPU 能够对变量进行快速的访问，变量的起始地址应该具有某些特征，即所谓的 “对齐”，比如4字节的 int 型，其起始地址应该位于 4 字节的边界上，即起始地址能够被 4 整除，也即 “对齐” 跟数据在内存中的位置有关。如果一个变量的内存地址刚好位于它长度的整数倍，它就被称为**自然对齐**。

- **为什么要字节对齐？**

  根本原因在于 CPU 访问数据的效率问题

  为了提高效率，计算机从内存中取数据是按照一个固定长度的。**以32位机为例，它每次取32个位，也就是4个字节**（每字节8个位)。字节对齐有什么好处？以int型数据为例，如果它在内存中存放的位置按4字节对齐，也就是说1个int的数据全部落在计算机一次取数的区间内，那么只需要取一次就可以了.

  ```C++
  union u1 {
      int a[5];  // 4*5 = 20
      char b;    // 1
      double c;  // 8
  };
  cout << sizeof(u1) << endl;  // 24 （8*3）
  // 原则1：union 中变量共用内存，而且以最长的为准
  // 原则2：占用的内存空间大小需要是结构体中占用最大内存空间的类型的整数倍
  
  struct u1{
      char a;   
      short b;   // 1 + 2 = 3 -> 4
      int c;     // 4
  };
  struct u2{
      char a;    // 1 -> 4
      int c;     // 4
      short b;   // 2 -> 4
  };
  cout << sizeof(u1) << endl;  // 8 = 4 * 2
  cout << sizeof(u2) << endl;  // 12 = 4 * 3
  
  
  struct s1 {
      int a[5];    
      char b;      // 20 + 1 = 21 -> 24
      double c;    // 8
  };
  cout << sizeof(s1) << endl;  // 32
  
  struct s2 {
      char b;      // 1 -> 8
      double c;    // 8 
      int a;       // 4 -> 8
  };
  cout << sizeof(s2) << endl;  // 24
  
  #pragma pack(4) 
  using namespace std; 
  struct example{ 
      char a;     // 1 -> 4
      double b;   // 8
      char c;     // 1 -> 4
  }test_struct;   
  sizeof(test_struct);        //16
  
  #pragma pack(4) 
  using namespace std; 
  struct example{ 
      int a;         // 4
      char b;        // 1 
      short int c;   // 2
      char d;        // 1
  }test_struct;
  sizeof(test_struct);       // 12
  
  #pragma pack(8) 
  using namespace std; 
  struct example{ 
      int a;        // 4
      char b;       // 1
      short int c;  // 2
      int d;        // 4
  }test_struct;           
  sizeof(test_struct);       // 12
  
  #pragma pack(n)表示，我们结构体成员所占用内存的起始地址需要是n的整数倍。
  规则一：对齐字节数 = min（成员起始地址应是n的倍数时填充的字节数， 自然对齐时填充的字节数）。
  规则二：同时满足占用的内存空间大小需要是结构体中占用最大内存空间的类型的整数倍。（当与规则一冲突时，优先考虑规则一）
  
  struct { 
      char b;   // 1
      double c; // 8
      int a;    // 4
  }__attribute__((packed)) test_struct;   //取消对齐
  sizeof(test_struct);    //13
  ```
  
  

### 20. 宏定义

```C++
#define A(x) (((x) < 0) ? -(x) : (x))

int m = -5;
cout << A(++m) << endl;   // 3   (((++m) < 0) ? -(++m) : (++m))
cout << m << endl;        // -3   m 前置自增了2次
```



### 21. 运算符优先级

```C++
// 解引用 * 与 ++
*p++;            // 先解引用，再自增
```



### 22. struct 与 class

C++ 中 struct 与 class 的区别：

- struct 默认的访问控制权限是 public，而 class 中默认的访问控制权限是 private
- 在继承关系中，struct 默认是公有继承，而 class 是私有继承。
- class关键词可以用于定义模板参数，和 typename 一样。但关键词 struct 不能用于定义模板参数。



### 23. C++ 和 C struct 区别

- C 的结构体内不允许有函数存在，C++ 允许有内部函数，且允许该函数是虚函数。

- C 的结构体对内部成员变量的访问权限只能是 public，而 C++ 允许 public，protected，private 三种。

- C 语言的结构体是不可以继承的，C++ 的结构体是可以从类或其他的结构体继承过来。

- C 结构体在定义时除非使用 typedef 取别名，否则之后定义变量都必须跟上 struct + 结构体名，而 C++ 结构体可以直接使用结构体名，不受限制。

  ```C++
  typedef struct Complex{
  　　int real;
  　　int image;
  } Complex;
  ```

  那么，在说明 Complex 变量的时候可以这样写 `Complex complex;`，但是如果没有 typedef 就必须用 `struct Complex complex;` 来声明。

  

### 24. struct 与 union 区别

- 结构体中的每个成员都有自己**独立**的地址，它们是同时存在的；而共同体中的所有成员**共同占用**同一段内存，它们不能同时存在；
- 在不考虑字节对齐的情况下，struct 变量的总长度等于所有成员长度之和。union 变量的长度等于最长的成员的长度；
- struct 的不同成员赋值是互不影响的；而对于 union 的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了。

### 25. 大端 小端

在小端模式中，低位字节放在低地址，高位字节放在高地址；在大端模式中，低位字节放在高地址，高位字节放在低地址。

写程序判断存储方式是大端还是小端：想办法取出一个字节的内容。

```C++
int a = 1;                  // a 占用 4 个字节
char *p = (char *)(&a);     // 指针 p 指向最低位的一个字节
if (*p == 1)
    cout << "little-endian" << endl;  // 4个字节（从低地址到高地址）1 0 0 0（小端）
else
    cout << "big-endian" << endl;     // 4个字节（从低地址到高地址）0 0 0 1（大端）
```

### 26  .hpp文件和.h文件的区别

一般来说 ，\*.h里面只有声明，没有实现，而\*.hpp文件中声明和实现都有，后者可以减少.cpp文件的数量。

==*.hpp要注意的问题有：==

a)不可包含全局对象和全局函数。

b)类之间不可循环调用。



<>的方式引用头文件，是引用编译器库中的头文件，而""的方式引用头文件，是以相对路径的方式引用自定义的头文件。

## 四.泛型编程

[泛型编程]：不再是针对某种类型，能适应广泛的类型。

如下的交换函数：

```c++
//交换int类型
void Swap(int& left, int& right)
{
    int temp = left;
    left = right;
    right = temp;
}
//利用C++支持的函数重载交换double类型
void Swap(double& left, double& right)
{
    double temp = left;
    left = right;
    right = temp;
}
```

使用函数重载虽然可以实现不同类型的交换函数，但是有以下几个不好的地方：

1.重载的函数仅仅是类型不同，代码复用率比较低，只要有新类型出现时，就需要用户自己增加对应的函数，使得代码重复性高，过渡冗余
2.代码的可维护性比较低，一个出错可能所有的重载均出错
那能否告诉编译器一个模子，让编译器根据不同的类型利用该模子来生成代码呢？

==泛型编程：编写与类型无关的通用代码，是代码复用的一种手段。模板是泛型编程的基础。==

模板分为如下两类:

- 函数模板
- 类模板

### 1.函数模板

函数模板代表了一个函数家族，该函数模板与类型无关，在使用时被参数化，根据实参类型产生函数的特定类型版本。

```c++
template<typename T1, typename T2,......,typename Tn>
返回值类型 函数名(参数列表)
{
    //……
}
注意：typename是用来定义模板参数关键字，也可以使用class(切记：不能使用struct代替class)
```

1.  template 是定义模板的关键字，后面跟的是尖括号 **< >**
2.  typename 是用来定义模板参数的关键字
3.  **T1, T2, ..., Tn** 表示的是函数名，可以理解为模板的名字，名字你可以自己取。

因此，交换函数就可以这样套用模板：

```c++
template<typename T>//或者template<class T>
void Swap(T& left, T& right)
{
    T tmp = left;
    left = right;
    right = tmp;
}
 
//我们在用 template< > 定义模板的时候，尖括号里的 typename 其实还可以写成 class：
template<class T>     // 使用class充当typename （具体后面会说）
void Swap(T& rx, T& ry) {
	T tmp = rx;
	rx = ry;
	ry = tmp;
}
虽然参数的名字我们可以自己取，但是我们一般喜欢给它取名为 T，因为 T 代表 Type（类型），有些地方也会叫 TP、TY、X ，或者 KV结构（key-value-store）
```

注意事项：**函数模板不是一个函数**，因为它不是具体要调用的某一个函数，而是一个模板。

#### (1)函数模板的原理

```c++
template<typename T>
void Swap(T& rx, T& ry) {
	T tmp = rx;
	rx = ry;
	ry = tmp;
}
 
int main(void)
{
	int a = 0, b = 1;
	double c = 1.1, d = 2.2;
	char e = 'e', f = 'f';
 
	Swap(a, b);
	Swap(c, d);
	Swap(e, f);
 
	return 0;
}
```

**问题：**我上述交换函数调用过程中的Swap都是调用的同一个函数吗？

当然不是，这里我**三次Swap不是调用同一个函数**，其实我Swap的时候根据不同的类型通过模板定制出专属你的类型的函数，然后再调用， 如下图：

![img](https://raw.githubusercontent.com/Howardcl/MyImage/main/4c1a0e8d9109433c9b49d44841ce4356.png)

 在编译器**编译阶段**，对于模板函数的使用，**编译器需要根据传入的实参类型来推演生成对应类型的函数以供调用**。比如：当用double类型使用函数模板时，编译器通过对实参类型的推演，将T确定为double类型，然后产生一份专门处理double类型的代码，对于字符类型也是如此。

补充：

​    通俗来理解，可以把模板理解成印章，我们不会把印的模具传递出去，而是印出来的纸；所以这里调用的当然不是模板，而是这个模板造出来的东西。

==而函数模板造出 "实际要调用的" 的过程，叫做模板实例化。==

编译器在调用之前会干一件事情 —— 模板实例化。

我们下面就来探讨一下模板实例化。

#### (2)函数模板的实例化

用不同类型的参数使用函数模板时，称为函数模板的实例化。模板参数实例化分为：隐式实例化和显式实例化。

- **隐式实例化**：让编译器根据实参推演模板参数的实际类型

- **显示实例化**：在函数名后的<>中指定模板参数的实际类型

1.**隐式实例化**

让编译器根据实参推演模板参数的实际类型

```c++
template<class T>
T Add(const T& left, const T& right)
{
	return left + right;
}
int main()
{
	int a1 = 10, a2 = 20;
	double d1 = 10.0, d2 = 20.0;
	Add(a1, a2); //编译器推出T是int
	Add(d1, d2); //编译器推出T是double
}
```

但是我调用的时候如若这样就会出错： 

```c++
int main()
{
    int a1 = 10, a2 = 20;
	double d1 = 10.0, d2 = 20.0;
	Add(a1, d1); //err 编译器推不出来
	/*
该语句不能通过编译，因为在编译期间，当编译器看到该实例化时，需要推演其实参类型
通过实参a1将T推演为int，通过实参d1将T推演为double类型，但模板参数列表中只有
一个T，编译器无法确定此处到底该将T确定为int 或者 double类型而报错
注意：在模板中，编译器一般不会进行类型转换操作，因为一旦转化出问题，编译器就需要背黑锅
    */
}
```

如果类型不匹配，编译器会尝试进行隐式类型转换，如果无法转换成功编译器将会报错。这里引发冲突编译器无法确定这里的T到底是int还是double。

此时有两种处理方式：

**法一：**用户自己来强制转化

```c++
int main()
{
	int a1 = 10, a2 = 20;
	double d1 = 10.0, d2 = 20.0;
    Add(a1, (int)d1); //强制类型转换。或者Add((double)a1, d1);
}
```

**法二：**使用显式实例化：（如下）

2.显示实例化

**定义：**在函数名后的 **< >** 里指定模板参数的实际类型。

简单来说，显式实例化就是在中间加一个尖括号 **< >** 去指定你要实例化的类型。（在函数名和参数列表中间加尖括号）

```
函数名 <类型> (参数列表);
```

 解决刚才的问题

```c++
template<class T>
T Add(const T& left, const T& right)
{
	return left + right;
}
int main()
{
	int a1 = 10, a2 = 20;
	double d1 = 10.0, d2 = 20.0;
    //显示实例化
	Add<int>(a1, d1); //double隐式类型转换成int 
	Add<double>(a1, d2); 
}
```

**总结：**

函数模板你可以让它自己去推，但是推的时候不能自相矛盾。

你也可以选择去显式实例化，去指定具体的类型。

**补充：模板支持多个模板参数**

```c++
template<class K, class V> //两个模板参数
void Func(const K& key, const V& value)
{
	cout << key << ":" << value << endl;
}
int main()
{
	Func(1, 1); //K和V均int
	Func(1, 1.1);//K是int，V是double
	Func<int, char>(1, 'A'); //多个模板参数也可指定显示实例化不同类型
}
```

5、**模板参数的匹配原则**

- **原则1：** 一个非模板函数可以和一个同名的函数模板同时存在，而且该函数模板还可以被实例化为这个非模板函数

如下代码会调用哪个Add函数？

```cpp
#include<iostream>
using namespace std;
//专门处理int的加法函数
int Add(int left, int right)
{
    printf("当然是直接用现成的啦+");
	return left + right;
}
//通用加法函数
template<class T>
T Add(T left, T right)
{
    printf("T");
	return left + right;
}
int main()
{
	Add(1, 2); //会调用哪个Add函数？
}
```

得出结论：编译器在调用时，**有现成的就调用现成的**，没有就套用模板。当然，我们也有办法强制让编译器走模板函数，如下:

```c++
void Test()
{
    Add(1, 2); // 与非模板函数匹配，编译器不需要特化
    Add<int>(1, 2); // 调用编译器特化的Add版本
}
```

 即用显示实例化会强制用模板

- **原则2：**对于非模板函数和同名函数模板，如果其他条件都相同，在调动时会优先调用非模板函数而不会从该模板产生出一个实例。如果模板可以产生一个具有更好匹配的函数， 那么将选择模板

```cpp
// 专门处理int的加法函数
int Add(int left, int right)
{
	return left + right;
}
// 通用加法函数
template<class T1, class T2>
T1 Add(T1 left, T2 right)
{
	return left + right;
}
void Test()
{
	Add(1, 2); // 与非函数模板类型完全匹配，不需要函数模板实例化
	Add(1, 2.0); // 模板函数可以生成更加匹配的版本，编译器根据实参生成更加匹配的Add函数
}
```

- **原则3：**模板函数不允许自动类型转换，但普通函数可以进行自动类型转换

假设有如下的函数模板：

```c++
#include<iostream>
using namespace std;
template<class T>
T* func(int n)
{ 
	return new T[n];
}
int main()
{
	//函数模板显示实例化
	int* p=func(10); 
	//int* p1 = func<int>(10);
	//double* p2 = func<double>(10);
}
```

 这里的模板就推不出T的类型。因此我们就要对其显示实例化

```cpp
#include<iostream>
using namespace std;
template<class T>
T* func(int n)
{ 
	return new T[n];
}
int main()
{
	//函数模板显示实例化
	//int* p=func(10); 
	int* p1 = func<int>(10);
	double* p2 = func<double>(10);
}
```

因此如果函数模板不能自动推演，就要显示实例化，指定模板参数。



### 2.类模板

#### (1)类模板的定义格式

```cpp
template<class T1, class T2, ..., class Tn>
class 类模板名
{
    // 类内成员定义
};
```

如下的栈示例：

```cpp
//typedef int STDataType; //C语言的做法
template<class T>
class Stack
{
public:
	Stack(int capacity = 10)
	{
		_a = new T[capacity];
		_capacity = capacity;
		_top = 0;
	}
	~Stack()
	{
		delete[]_a;
		_capacity = _top = 0;
	}
private:
	T* _a;
	int _top;
	int _capacity;
};
```



#### (2)类模板的实例化

类模板实例化与函数模板实例化不同，类模板实例化需要在类模板名字后跟<>，然后将实例化的类型放在<>中即可，**类模板名字不是真正的类，而实例化的结果才是真正的类**。

```cpp
Vector类名，Vector<int>才是类型
```

```c++
int main()
{
	Stack<int>st1; //int类型
	Stack<double>st2;//double类型
}
```

上述可以看出类模板是要显示实例化的，而我函数模板是不需要自己显示实例化的，编译器会自动帮我推演

```cpp
#include<iostream>
using namespace std;
 
template<class T>
class Stack {
public:
	Stack(T capacity = 4)
		: _top(0)
		, _capacity(capacity) {
		_arr = new T[capacity];
	}
	~Stack() {
		delete[] _arr;
		_arr = nullptr;
		_capacity = _top = 0;
	}
private:
	T* _arr;
	int _top;
	int _capacity;
};
 
int main(void)
{
	Stack<int> st1;      // 指定存储int
	Stack<double> st2;   // 指定存储double
 
	return 0;
}
```

① Stack 不是具体的类，是编译器根据被实例化的类型生成具体类的模具。

```c++
template<class T>
class Stack {...};
```

类模板名字不是真正的类，而实例化的结果才是真正的类。

② Stack 是类名，Stack<int> 才是类型：

```c++
Stack<int> s1;
Stack<double> s2;
```

#### (3)类外定义类模板参数

思考问题：下面的代码为什么会报错？（类定义正确）

```cpp
#include<iostream>
using namespace std;
template<class T>
class Stack {
public:
	Stack(T capacity = 4)
		: _top(0)
		, _capacity(capacity) {
		_arr = new T[capacity];
	}
	void Push(const T& x);
	// 这里我们让析构函数放在类外定义
	~Stack();
private:
	T* _arr;
	int _top;
	int _capacity;
};
 
// 类模板中函数放在类外进行定义时，需要加模板参数列表
template <class T>
//正确做法：这里要加Stack<T>::~Stack() { 
Stack::~Stack() {   // Stack是类名，不是类型！ Stack<T> 才是类型，
	delete[] _arr;
	_arr = nullptr;
	_capacity = _top = 0;
}

//正确做法：这里要加template <class T>
void Stack<T>::Push(const T& x) {
	;
}
int main() {
	return 0;
}
```

#### (4)模板的分离编译

模板的声明和定义是可以分离的（前提是**声明和定义在一个文件**）。像下面这样就可以：

```cpp
//函数模板的声明
template<typename T>
void Swap(T& left, T& right);
//类模板的声明
template<class T>
class Vector
{
public:
	Vector(size_t capacity = 10);
private:
	T* _pData;
	size_t _size;
	size_t _capacity;
};
 
//函数模板的定义
template<typename T> //定义的时候也要给模板参数
void Swap(T& left, T& right)
{
	T tmp = left;
	left = right;
	right = tmp;
}
//类模板的定义
template<class T> //定义的时候也要给模板参数
Vector<T>::Vector(size_t capacity)
	: _pData(new T[capacity])
	, _size(0)
	, _capacity(capacity)
{}
```

**模板不支持声明和定义放到两个文件中的（xxx.h和xxx.cpp），会出现链接错误。** **为什么不支持声明和定义分别放到两个文件呢？**

解答：源文件在生成可执行程序的过程会经历**预处理、编译、汇编、链接**这四大模块。

![img](https://raw.githubusercontent.com/Howardcl/MyImage/main/1d86d116c5c744b8ae99b65197b7d7ab.png)

我template.i在编译后生成对应的.s文件以及后续的.o文件其实都是空的，编译器下不了手，因为无法确定T类型，这也就导致符号表是空的，没有地址。而调用的地方就没问题，因为main函数里头已经实例化显示出了T的类型。随后就去符号表里找到对应函数的地址，但是找不到。所以链接就会出错。


解决办法1：针对要使用的模板类型显示实例化指定，你调用函数的地方有哪些类型，就要指定显示实例化哪些类型。加上了显示实例化，此时就能链接上了

（但是这要模板有何用，还不如直接给出确定类型，所以非常不推荐）

解决办法2：将声明和定义放到一个新文件 "xxx.hpp" 里面（其实就是只能在一个文件的意思，没有解决办法~~）


## 五. 操作系统

### 1. I/O模型

`I/O`模型共有五种：阻塞IO、非阻塞IO、信号驱动IO、IO复用、异步IO。其中，前四种都是同步IO。

- #### 同步 IO vs 异步 IO

**同步和异步**是指访问数据的机制，同步指主动请求并等待IO操作的完成，异步指主动请求数据后便可以继续处理其他任务，当IO操作完成时内核自会通知。

同步关注IO事件，IO操作由用户程序自己来完成；异步关注IO完成事件，IO操作由内核来完成。

- #### 阻塞 IO vs 非阻塞 IO

  **阻塞和非阻塞**是当进程访问的数据如果尚未就绪时，进程是否要暂停等待。

  （比如调用`accept()`、`send()`、`recv()`等系统调用或库函数）阻塞方式是要等待IO事件就绪才能返回，继而往下执行；而非阻塞是立即返回，不管IO事件是否就绪。非阻塞IO需要反复轮循尝试数据是否就绪，防止进程被阻塞，最大的好处在于可以在一个进程中同时处理多个IO操作。不过，轮流对每个文件描述符调用读写方法，不管这些文件描述符有无事件就绪，都要询问一遍，假如大部分文件描述符并没有事件就绪，那么进程便会浪费大量CPU时间用于检查文件描述符，使得进程处于忙碌等待状态。

- #### IO 复用

![image-20210830153330582](https://i.loli.net/2021/08/30/PL8islkXe6NUpHG.png)

### 2. 并发模型

- **同步的部分：**线程池的工作线程处理业务逻辑。无任务时睡眠在任务队列上，当有任务到来时，通过竞争互斥锁获得任务接管权，从任务队列中取出任务，解析HTTP请求报文，生成HTTP响应报文，找到客户端请求的资源

- **异步的部分：**主线程进行I/O操作，具体为监听所有套接字文件描述符上的事件，接收新的客户连接，往`epoll`内核事件表中注册新连接套接字上的读写事件，读取客户端发来的HTTP请求报文，将其封装任务对象放到任务队列中去，向客户端发送HTTP响应报文及请求的资源

- #### `reactor`、`proactor`、主从`reactor`模型区别？

  - **`Reactor`模式：**

    主线程只负责监听文件描述符上有无事件发生，若有则立即通知工作线程，将套接字上的可读可写事件放入任务队列中；

    而读写数据、接收新连接等I/O操作以及处理客户请求的均在工作线程当中完成

  - **主从`reactor`模式：**

    与上一种的区别在于，上一种是在单线程中运行`reactor`，这里是在多线程中运行`reactor`。

    主反应堆线程只处理连接事件（accept()获取连接套接字）；已连接套接字上的I/O事件交给从反应堆线程完成

  - **`Proactor`模式：**

    主线程负责读写数据、接收新连接等I/O操作；工作线程只负责处理业务逻辑

### 3. **临界资源**

临界资源一定是共享资源，每个进程都能访问。但共享资源不一定是临界资源，因为为了数据安全，临界资源限定了每次只允许一个进程访问。

- [ ] 临界资源是每个进程都可以访问的临界资源
- [ ] 临界资源会引起进程阻塞
- [ ] 临界资源需要互斥访问
- [ ] 每个进程中对临界资源进行访问的那段代码成为**临界区**，每次只允许一个进程进入临界区



### 4. **进程 线程 协程**

**为什么多进程之间的数据共享比多线程更加复杂？**

不同进程有不同的**页表**，对应着不同的**物理地址空间**，因此进程间通信需要使用IPC或者socket。而线程可以共享进程的地址空间，所以进程间通信比线程间通信复杂。

**为什么多线程的创建、切换和销毁比多进程快？**

进程创建是操作系统要为它分配内存，销毁时收回。而线程不需要，所以线程的创建与销毁更快。  

**为什么计算密集的任务优先选择多线程？**

当存在大量计算需求的时候，比如需要并发计算时，会频繁的切换进程/线程。而线程切换的成本小于进程，因此选择多线程模型。

**单个线程崩溃为什么会导致整个应用程序退出？**

多线程没有内存隔离，同一进程中的不同线程共享地址空间，所以一个线程挂掉可能会导致整个进程挂掉。



**用多进程还是多线程？**

引入多进程的目的是为了提供并发能力，但进程的创建需要新分配虚拟地址空间、页表、物理内存等等。引入多线程的目的是复用进程的资源。

多线程代表：redis

多进程代表：nginx

多进程更加的健壮，多线程的话，只要其中一个线程挂掉了，整个进程就挂了。

每个线程私有的资源有：（1）线程ID（2）寄存器组的值（3）线程的栈（4）错误返回码errno值（5）线程的信号屏蔽码（6）线程的优先级（密集型计算，拿到更多的CPU）



**为什么需要线程池？**

两点：（1）通过预先创建线程，通过异步处理来提高响应速度。（2）同时通过统一调配线程资源，可以降低线程的重复创建问题，提高线程的利用率，中心化管理有利于对资源的有效控制，防止滥用。

<img src="https://i.loli.net/2021/11/15/XM5zmc2GCVQNF3P.png" alt="image-20211115170903062" style="zoom:80%;" />

<img src="https://i.loli.net/2021/11/15/jdrtLUgBARCOPWV.png" alt="image-20211115171017885" style="zoom: 80%;" />



**线程池开多少个线程比较合适？是不是开得越多越好？**

**线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。**

```c++
最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目
```

 a）假如是业务时间长集中在IO操作上，也就是**IO密集型**的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务。这类任务的CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。常见的大部分任务都是IO密集型任务，比如**Web应用**。对于IO密集型任务，任务越多，CPU效率越高(但也有限度)。

```C++
一般配置线程数 = CPU总核心数 * 2 + 1
```

 b）假如是业务时间长集中在计算操作上，也就是**计算密集型**任务，线程池中的线程数设置得少一些，减少线程上下文的切换（假设你的任务非常消耗CPU, 那么现在每个CPU都被占满了, 你再增加线程个数, 只能降低系统的效率, 因为线程还需要切换）。要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

```C++
 一般配置线程数 = CPU总核心数 + 1    (+1 是为了利用等待空闲)
```



<img src="https://i.loli.net/2021/11/15/aVrEqCY3Bo6i7kP.png" alt="image-20211115172237945" style="zoom:80%;" />

- #### 进程的由来

  ##### **程序是什么？进程是什么？**

  程序是一组有序的指令集合。进程是程序的一次执行，是系统资源分配的基本单位。

  - **动态性：**程序是静态的，存放在某种介质上（硬盘），而进程是动态的，有生命周期。

  - **并发性：**程序没有 PCB，不能参加独立并发执行

  - **独立性：**进程是系统分配资源的基本单位，是一个可以独立运行的基本单位，凡是没有建立 PCB 的程序都不能作为一个独立的单位运行

  - **异步性：**实质程序按照异步的方式运行，即按各自独立的不可预知的速度向前，也正是由于这点，才导致了传统意义上的程序如果参与并发执行会导致结果的不可再现性，为了使程序在运行的时候有异步性当是同时也保证程序并发执行的结果是可再现的，这才引入了进程并配备了进程同步机制。

  ##### **为什么引入进程？作用是什么？**

  引入进程的目的是为了解决程序并发执行所导致的问题。

  并发执行中，系统的资源被各个程序所共享，这导致程序的状态会受到其他程序的影响，而且程序不能保留现场，中断了无法恢复。

  进程的中有 PCB，每个程序都能独立运行，不受彼此的影响，并且中断了能恢复。

  ##### 进程为什么能够并发执行？

  系统为进程配备了一个专门的数据结构 PCB（进程控制块），并发执行的程序其实是“走走停停”的执行，当进程停下时，可以将其现场信息保存在PCB中，下次调度时，再从PCB中恢复CPU现场并继续执行，而传统的程序无法做到。

  **进程的代价**

  进程控制块的内存开销，进程间切换，进程同步，以及进程间通信的事件开销。

- #### **进程 vs 线程**

  - **存在关系**

    线程是进程的基本执行单元，一个进程的所有任务都在线程中执行，进程想执行任务，必须得有线程，进程至少有一条线程。**进程和线程都是通过系统调用` clone() `创建的**

  - **内存 资源分配**

    进程是资源分配的基本单位，资源是分配给进程的，进程拥有独立的内存单元，因此进程间不会相互影响。

    而线程没有，它们共享进程的资源：共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储），一个线程挂掉将导致整个进程挂掉。

    不过线程也有独享的内容：一个独立的程序计数器（PC）、栈、和一组寄存器。

  - **通信**

    进程间通信`IPC`（管道、消息队列、共享内存、信号、套接字），

    同进程中的线程具有相同的地址空间，它们的同步和通信实现比较容易。线程间可以直接读写进程数据段（如全局变量）—— 不过也需要同步和互斥手段的辅助，以保证数据的一致性。

  - **CPU调度**

    线程是CPU调度的基本单位，内核调度的是线程，不是进程。

  - **系统开销**

    创建、销毁和切换进程的开销远大于创建、销毁和切换线程的开销。

    创建进程时，系统要为其分配内存空间、I/O设备等资源；销毁进程时，系统要回收资源；切换进程时，要保存当前进程CPU环境和新被调度运行的进程的CPU环境的设置。

    而切换线程只需保存和设置少量寄存器的内容。



- #### 什么是协程？与线程的区别？

  可以简单地认为协程是一种用户态线程。

  **线程与协程的相同点：**

  都有独立的寄存器上下文和运行栈，对程序直观的效果就是，代码可以在协程里面正常的运行，就像在线程里面一样。

  **线程与协程的区别：**

  （重点关注运行栈管理模式和协程调度策略）协程的创建和调度比线程轻量得多，而且协程的通信与同步可以时无锁的，任意时刻都可以保证只有本协程在操作线程内的资源。

- #### **为什么需要协程？**

  - ##### 时间上 - 降低系统切换开销

    当线程等待 `IO` 时，会阻塞当前线程，切换到其他线程，这样在当前线程等待`IO`的过程中，其他线程就能继续执行。

    进程/线程每次阻塞和切换都要陷入系统调用，先让 CPU 跑操作系统的调度程序，由调度程序决定跑哪一个进程/线程，所以线程的切换是从用户态到内核态。

    而协程有自己的寄存器上下文和栈，调度切换时将寄存器上下文和栈保存到其他地方，切换回来的时候恢复先前保存的上下文即可，所以协程的切换和调度就在用户态内完成，相较之下，它的调度切换开销会小很多。

  - ##### 空间上 - 减少占用内存

    线程创建之初就要指定栈空间，协程需要多少才用多少，使用的内存可以动态变化，占用的内存更少。

    协程运行在线程上，通过时分复用的方式可以在一个线程上运行多个协程，在不增加线程数量的条件下，能处理更多的任务。

    比如说，启动 100 个线程，每个线程上运行 100 个协程，就能同时处理 10000 个任务。

  - ##### 通信与同步问题

    对于线程来说，抢占式调度无法确定线程的执行顺序，格外要小心处理同步问题。

    对于协程来说，由用户来决定任务让给谁来执行，也就是说协程的执行顺序是可以确定的，可以保证任一时刻只有本协程在操作线程内的资源。

- #### 协程的使用场景

  在有大量 `IO`操作业务的情况下，采用协程替换线程，可以达到很好的效果。在线程阻塞等待`IO`的过程中，线程上的协程能处理任务。

  协程只有在`IO`密集型任务中才能发挥作用，对计算密集型任务没有太大好处。

- #### 协程的注意事项

  在协程中不能使用导致阻塞的函数，比如`pthread_mutex`、`sleep`（可以用`poll(NULL, 0, timeout)`代替），因为这样会导致当前协程以及其他绑定在同线程上的协程都阻塞。

  在操作跨线程数据的时候，需要使用线程安全级别的函数。

  

### 4. 千万高并发-协程

- #### 协程的调度

  你可以定义一种调度策略，使得协程在不同的线程间切换，但是这样做会带来昂贵的切换代价。`libco` 的协程调度策略很简洁，**单个协程限定在固定的线程内部，仅在网络 `IO` 阻塞等待时候切出，在网络 `IO` 事件触发时候切回**，也就是说在这个层面上面可以认为协程就是有限状态机，在事件驱动的线程里面工作。

- #### **如何实现千万级别？**

  `libco` 默认是每一个协程独享一个运行栈，在协程创建的时候，从堆内存分配一个固定大小的内存作为该协程的运行栈。如果我们用一个协程处理前端的一个接入连接，那对于一个海量接入服务来说，我们的服务的并发上限就很容易受限于内存。

  所以量级的问题就转换成了怎样高效使用内存的问题。

  为了解决这个问题，`libco` 采用的是共享栈模式。（传统运行栈管理有 `stackfull` 和 `stackless` 两种模式）

  **简单来讲，是若干个协程共享同一个运行栈。**

  **具体实现：协程共享栈模式下，线程内分为多个协程组，同一个协程组内的协程共用一个协程栈。栈内存拷贝只发生在同一个协程组内的协程间切换。**

  同一个共享栈下的协程间切换的时候，需要把当前的运行栈内容拷贝到协程的私有内存中。为了减少这种内存拷贝次数，共享栈的内存拷贝只发生在不同协程间的切换。当共享栈的占用者一直没有改变的时候，则不需要拷贝运行栈。

  ![image-20210901005159517](https://i.loli.net/2021/09/01/PXcdGDIs4iE5WVK.png)

  #### **共享栈的原理**：

  `libco` 默认模式 (`stackfull`) 满足大部分的业务场景，每个协程独占 `128k` 栈空间，只需 `1G` 内存就可以支持万级协程。 而共享栈是 `libco` 新增的一个特性，可以支持单机**千万**协程，应对**海量连接**特殊场景。

  实现原理上，共享栈模式在传统的 `stackfull` 和 `stackless `两种模式之间做了个微创新，**用户可以自定义分配**若干个共享栈内存，协程创建时**指定**使用哪一个共享栈。

  #### 不同协程之间的切换、 如何主动退出一个正在执行的协程？

  我们把共享同一块栈内存的多个协程称为协程组，协程组内不同协程之间切换需要把栈内存拷贝到协程的私有空间，而协程组内同一个协程的让出与恢复执行则不需要拷贝栈内存，可以认为共享栈的栈内存是“写时拷贝”的。

  共享栈下的协程切换与退出，与普通协程模式的 `API `一致，`co_yield `与 `co_resume`，`libco` 底层会实现共享栈的模式下的按需拷贝栈内存。

- #### 全局变量 VS 私有变量

  在 `stackfull` 模式下面，局部变量的地址是一直不变的；而 `stackless` 模式下面，只要协程被切出，那么局部变量的地址就失效了，这是开发者需要注意的地方。

  `libco` 默认的栈模式是每一个协程独享运行栈的，在这个模式下，开发者需要注意栈内存的使用，**尽量避免 `char buf[128 \* 1024]` 这种超大栈变量的申请**，当栈使用大小超过本协程栈大小的时候，就可能导致**栈溢出**的 `core`。

  而在共享栈模式下，虽然在协程创建的时候可以映射到一个比较大的栈内存上面，但是当本协程需要让出给其它协程执行的时候，已使用**栈的拷贝保存开销**也是有的，因此最好也是**尽量减少大的局部变量使用**。更多的，共享栈模式下，因为是多个协程共享了同一个栈空间，因此，用户需要注意**协程内的局部栈变量地址不可以跨协程传递**。

  协程私有变量的使用场景与线程私有变量类似，协程私有变量是全局可见的，不同的协程会对同一个协程变量保存自己的副本。开发者可以通过我们的 `API` 宏声明协程私有变量，在使用上无特别需要注意的地方。

  多进程程序改造为多线程程序时候，我们可以用 __thread 来对全局变量进行快速修改，而在协程环境下，我们创造了协程变量 ROUTINE_VAR，极大简化了协程的改造工作量。

  关于协程私有变量，因为协程实质上是线程内串行执行的，所以当我们定义了一个线程私有变量的时候，可能会有重入的问题。比如我们定义了一个 `__thread` 的线程私有变量，原本是希望每一个执行逻辑独享这个变量的。但当我们的执行环境迁移到协程了之后，同一个线程私有变量，可能会有多个协程会操作它，这就导致了变量冲入的问题。为此，我们在做` libco `异步化改造的时候，把大部分的线程私有变量改成了协程级私有变量。协程私有变量具有这样的特性：当代码运行在多线程非协程环境下时，该变量是线程私有的；当代码运行在协程环境的时候，此变量是协程私有的。底层的协程私有变量会自动完成运行环境的判断并正确返回所需的值。

### 5. 进程控制块 PCB

**PCB 是什么？**

`linux`中的进程控制块(**`PCB`**)是**一个结构体 `task_struct`**，包含了进程相关的所有信息。每个线程（`linux`中进程和线程的区分并不明显）对应一个 `task_struct`，存放在**内核栈**的尾端，内核通过**任务队列（一个循环双向链表）**来组织所有线程的进程描述符。内核把进程的列表存放在叫做**任务队列**的双向循环链表中。

（1）是系统用来控制和管理进程的**一个数据结构**，是**进程存在的唯一标志**，每个进程都有，创建进程时生成 PCB，销毁时回收 PCB，进程就随之消失了；

（2）PCB 中记录当前情况和管理进程运行的全部信息，包括进程当前的状态，进程的标识符`pid`，进程的亲属信息，进程切换时的硬件上下文，进程的地址空间。

（3）虽然进程间共享内核空间，但**不共享 PCB**。

（4）PCB 的组织方式：所有 PCB 保留在一张线性表中，开销小实现简单，但每次扫描都需要扫描整张表。

（5）链接方式：将具有相同状态的进程的 PCB 分别通过 PCB 中的链接关键字链接成一个队列，从而形成就绪队列、阻塞队列、运行队列等。

<img src="https://i.loli.net/2021/08/31/UeTEFjKzbBiMxH1.png" alt="image-20210831194904893" style="zoom:80%;" />



**PCB 的作用是什么？**

- 实现间断性运行方式

  在多道程序环境下，程序采用的是走走停停的方式运行的，当进程由于阻塞而停止运行时，系统将**CPU现场保留**在被中断进程的PCB中，当该进程再次被调度时就可以恢复现场；

- 实现与其他进程的同步和通信
- 提供进程管理所需的信息

- 提供进程调度所需的信息

  只有处于就绪态的程序才能被调度执行，而在 PCB 中就提供了进程当前所处的**状态信息**，还有进程的优先级，甚至进程的等待事件和已经执行的时间。



### 6. 进程五状态

<img src="https://i.loli.net/2021/08/26/5qaoDzjW3f7pHnJ.png" alt="image-20210826214234989" style="zoom:80%;" />

- **创建状态**：进程正在被创建

  创建进程的过程：

  进程申请一个空白的 `PCB`，并向其中加入控制和管理进程的信息，然后为该进程分配所需资源，然后将进程插入就绪队列中。如果为该进程分配的资源尚未得到满足，比如系统内存不够将进程插入其中，则此时就可能推迟新进程的提交，经常就不能被调度运行，仍然处于创建状态。

- **就绪状态：**进程被加入到就绪队列中等待`CPU`调度运行

- **执行状态：**进程正在被运行

- **等待阻塞状态：**进程由于某种原因，比如等待`I/O`暂时不能运行

- **终止状态：**进程运行完毕

  终止的原因：程序执行完毕；被操作系统终结；被其他有终止权的程序终结。

  终止步骤：系统将 PCB 清零并回收空白 PCB。

### 7. 进程调度算法

进程调度所需的信息：

- 进程的优先级
- 进程进入阻塞状态的原因
- 进程档当前的状态

**进程调度算法：多个进程抢占`CPU`的规则**，进程每次阻塞和切换都要陷入系统调用，先让CPU跑操作系统的调度程序，让调度程序决定该跑哪一个进程。

- ① *先来先服务（`FCFS`）；*【非抢占式】：按照作业进入系统后备作业队列的**先后次序**来挑选作业，加入就绪队列，等待执行。

- ② *短作业优先（`SJF`）；*【非抢占式】：该算法每次从**后备作业队列**中挑选估计**服务时间最短**的一个或几个作业，将他们调入内存，分配必要的资源，创建进程并放入就绪队列。

- ③**【可以掠过不说，不太常见】**最短剩余时间优先（`SRTF`）；【非抢占式】：首先执行剩余处理时间最少的过程；

- ④ *高响应比优先（`HRRF`）；*【抢占式】：每次进行作业调度时，先计算后备作业队列中每个作业的**响应比**，挑选最高的作业投入系统运行。

  `响应比 =（等待时间 + 服务时间）/ 服务时间 = 等待时间 / 服务时间 + 1`。

- ⑤ *优先级调度（`Priority`）；*【抢占式或非抢占式】：

  - 非抢占式：系统一旦把处理器分配给就绪队列中优先权最高的进程后，该进程就占有处理器一直运行下去，直到该进程完成或因发生事件而阻塞，才退出处理器。
  - 抢占式：系统同样把处理器分配给当前就绪队列中优先权最高的进程，使之执行。但在其执行期间，仍然会不断有新的就绪进程进入就绪队列，如果出现某个进程，其优先权比当前正在执行的进程的优先权还高时，进程调度程序就会立即暂停当前进程的执行，而将处理器收回，并将处理器分配给新出现的优先权更高的进程，让其执行。

- ⑥**【可以掠过不说，不太常见】**时间片轮转（`RR`）。【抢占式】：系统把所有就绪进程按先入先出的原则排成一个队列。新来的进程加到就绪队列末尾。每当执行进程调度时，进程调度程序总是选出就绪队列的队首进程，让它在`CPU`上运行一个时间片的时间。时间片是一个小的时间单位，通常为`10~100ms`数量级。当进程用完分给它的时间片后，系统的计时器发出时钟中断，调度程序便停止该进程的运行，把它放入就绪队列的末尾；然后，把`CPU`分给就绪队列的队首进程，同样也让它运行一个时间片，如此往复。

### 8 死锁

**系统产生死锁的原因**

- [x] 进程太多，系统无法处理
- [ ] 进程中线程太多
- [ ] 线程太多，系统无法处理
- [x] 进程调度不当，使进程推进顺序不合理

**死锁是指两个及以上进程因竞争临界资源而造成的一种僵局，一个进程等待一个已经被占用且永不释放的资源，若无外力作用，这些进程都无法向前推进。产生死锁的根本原因是系统能够提供的资源个数比要求该资源的进程数要少。产生死锁的基本原因可以分为两类：资源竞争和进程推进顺序不合理。**

产生死锁的四个**必要条件**：

- 互斥：访问的是临界资源，一次只能被一个进程访问
- 占有并等待：一个进程请求被其他进程所占用的资源而阻塞，且对自己已经获得的资源保持不放
- 非抢占（不可剥夺）：进程已获得的资源，在使用完之前不能被强行剥夺，只能由该资源的占有者自行释放
- 循环等待：存在一种进程首尾相接的循环链，链中每个进程都在等待下一个进程所持有的资源，造成所有进程处于永久等待的状态。

**处理策略：**

- <strong style="color:red;">鸵鸟策略</strong> 

  - 在死锁发生**概率极低**的情况下，和发生死锁时不会对用户**造成很大影响**时可以直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

- <strong style="color:red;">预防死锁形成</strong> 

  - 基本思想就是围绕形成死锁的四个必要条件，通过破坏这四个条件最终预防死锁的形成。
    - 针对必要条件一【互斥】：因为资源本身并不具有同时被多个进程访问的属性，所以意义不大。
    - 针对必要条件二【占有并等待】：进程运行之前一次性向系统申请所有需要的资源。【缺点：降低了资源的利用率和系统的并发性】
    - 针对必要条件三【不可剥夺】：在请求新的资源不得到满足，必须释放占用的资源；
    - 针对必要条件四【环路等待】：对所有资源线性编号，所有进程对资源的请求必须按照序号递增的顺序申请        【即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源】

- <strong style="color:red;">避免死锁形成</strong> 

  - 动态地检测资源分配状态，以**确保系统处于安全状态**，只有处于安全状态时才会进行资源的分配。

    - 安全状态：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。

  - **举例：银行家算法**

    - 客户申请的贷款有限的，每次申请需要声明最大资金量，银行家在能够满足贷款时，都应带给用户贷款，用户使用贷款后，能及时归还贷款

    - 【**1**所需总资源表】（用户）、【**2**已分配资源表】（银行）、【**3**可分配资源表】（银行）

      - 【**4**还需分配资源表】=【**1**所需总资源表】（用户）--【**2**已分配资源表】（银行）

      - 将【**3**可分配资源表】（银行）依次对照【**4**还需分配资源表】进行分配资源

        <img src="https://raw.githubusercontent.com/SuZhaixing/img/master/img/20210205212301.png" alt="image-20210116163327921" style="zoom:67%;" />

- <strong style="color:red;">解除已经形成的死锁</strong> 

  - 检测是否形成死锁：检测有向图是否存在环；

  - 解除方法：

    ① 设置回滚点和还原点：发生死锁时让某些进程回退到足以解除死锁的地步；

    ② 杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行；

    ③【**选说：建议不说**】抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态。



### 9. 内核空间 用户空间

内核空间和用户空间是虚拟地址空间的两部分。对Linux系统而言，最高的1G字节由内核使用，低3G字节由进程使用。进程的3G用户空间是相互独立的，1G内核空间是所有进程共享的，只是每个进程的PCB进程控制块不一样。

**为什么要区分内核空间和用户空间？**

本质上是为了提高操作系统的稳定性和可用性。对于Linux这种多任务系统而言，这种设计可以隔离操作系统代码与应用程序代码，毕竟操作系统代码要健壮得多。单个应用程序出现错误也不会影响到操作系统的稳定性，其他的程序还能正常运行。

CPU指令中，有些指令很危险，一旦错用会导致系统崩溃（比如清内存，设置时钟），如果允许所有程序都能使用这些指令，系统很容易崩溃。因此将CPU分了等级，限定那些危险的指令只允许操作系统使用（运行在内核态），普通应用程序无法使用（运行在用户态）。

**内核态 vs 用户态**

进程运行在内核空间时就处于内核态；运行在用户空间就处于用户态。

内核态下，进程运行在内核空间中，此时CPU可以执行任何指令。运行的代码不受任何限制，可以自由访问任何有效地址，也可以直接进行端口的访问。

用户态下，进程运行在用户地址空间中，被执行的代码要受到CPU的诸多检查，只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址。

以前的DOS系统没有内核空间，用户空间，内核态，用户态的概念，可以认为所有代码都运行在内核态，因此用户编写的应用程序很容易让系统崩溃。

**如何从用户空间进入内核空间？**

系统调用、软中断和硬件中断。

**什么情形下需要进入内核态？**

进行系统资源管理时，比如读写磁盘文件，分配回收内存，从网络接口读写数据等。这些操作应用程序无法直接操作，只能通过内核提供的接口来完成。内核空间中，CPU可以执行任何指令。先把数据读写到内核空间，再拷贝到内核空间，并从内核态切换到用户态。

从内核空间和用户空间的角度看一看整个 Linux 系统的结构。它大体可以分为三个部分，从下往上依次为：硬件 -> 内核空间 -> 用户空间。

**在硬件之上，内核空间中的代码控制了硬件资源的使用权，用户空间中的代码只有通过内核暴露的系统调用接口(System Call Interface)才能使用到系统中的硬件资源。**

实际上我们可以将每个处理器在任何指定时间点上的活动概括为下列三者之一：

- 运行于用户空间，执行用户进程。
- 运行于内核空间，处于进程上下文，代表某个特定的进程执行。
- 运行于内核空间，处于中断上下文，与任何进程无关，处理某个特定的中断。

以上三点几乎包括所有的情况，比如当 CPU 空闲时，内核就运行一个空进程，处于进程上下文，但运行在内核空间。

说明：Linux 系统的中断服务程序不在进程的上下文中执行，它们在一个与所有进程都无关的、专门的中断上下文中执行。之所以存在一个专门的执行环境，就是为了**保证中断服务程序能够在第一时间响应和处理中断请求，然后快速地退出。**



### 10. 中断

- **什么是中断？**

  中断是CPU对系统发生的某个事件做出的**一种反应**（会打断CPU让其执行其他任务），这种反应的**处理动作**是：CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处去继续执行原来的程序。

- **中断有哪些？**

  - **外中断**

    由CPU执行指令外的事件引起，如`I/O`完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

  - **异常**

    由CPU内部事件或程序执行中引起的中断，如程序非法操作、地址越界、浮点溢出（除法中分母出现0）。

  - **陷入**

    用户程序中使用了系统调用引起。



### 11. 4 种锁机制

- **互斥锁`mutex`**

  （1）任何时刻只允许一个线程访问资源

  （2）获取锁操作失败时，线程进入睡眠状态，等待锁释放时被唤醒

- **读写锁`rwlock`**

  （1）分为读写锁。同一时刻只允许一个写者，其他读者和写者阻塞；同一时刻允许多个读者；写者优先于读者；

  （2）获取锁操作失败时，线程进入谁卖你状态，直到锁被释放

  （3）适用于读操作频繁的场景

- **自旋锁`spinlock`**

  （1）任何时刻只允许一个线程访问资源

  （2）获取锁操作失败时，线程不进入睡眠状态，在原地自旋等待锁释放（**不放弃CPU时间片**，不停地再次尝试获取锁，如果失败就再次尝试直至成功为止）

- **轻量读写锁`RCU`**

  （1）多个读者可以同时读取共享的数据

  （2）更新者更新共享的数据时需要复制一份，对副本进行修改，修改完将原来的共享数据替换为新的副本，对旧数据的销毁等待所有读者都不再引用旧数据时进行

  （3）读者无需同步开销，既不需要获得锁，又不使用原子指令，不会导致锁竞争，因此无需考虑死锁问题

  （4）写者的同步开销较大，需要复制被修改的数据，还必须使用锁机制同步并行其他写者的修改操作

  （5）适用于读操作多，写操作少的场景

RCU与读写锁都支持多个读者同时访问临界区，并且比读写锁更为轻量，性能更好。

**(1) 互斥锁 vs 读写锁**

- **互斥锁：**

  `mutex`，保证再任何时刻都只能又一个线程访问该对象。当获取锁操作失败时，线程进入睡眠状态，等待锁释放时被唤醒。

- **读写锁：**

  `rwlock`，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其他获取写锁失败的线程都会进入睡眠状态，直至写锁释放时被唤醒。**注意：写锁会阻塞其他读写锁。当一个线程获得写锁时，读锁也不能被其他线程获取。写者优先于读者**，一旦有写者，则后续读者必须等待，唤醒时优先考虑写者。适用于读取数据的频率远远大于写数据频率的场合。

- **二者区别：**

  （1）读写锁区分读者和写者，互斥锁不区分

  （2）互斥锁同一时间只允许一个线程访问资源，无论读写；读写锁分情况，同一时间允许多个读者同时读取，但只允许一个写者写

**(2) 自旋锁 vs 非自旋锁**

![image-20210826195720589](https://i.loli.net/2021/08/26/6GPJjHV2hxSw83I.png)

- **自旋锁：**获取锁操作失败时，不会放弃CPU时间片，而是通过自旋等待锁的释放，也就是说会不停地尝试再次获取锁，如果失败就再次尝试，直至成功为止。
- **非自旋锁：**获取锁操作失败时，将线程切换状态，让线程休眠，CPU就可以在等待锁释放这段时间去做其他事情。直到之前持有这把锁的线程释放了锁，CPU再把之前的线程恢复回来，让这个线程再次尝试获取这把锁，如果再次失败，就再次让线程休眠。

**自旋锁和非自旋锁最大的区别在于：当获取锁操作失败时，线程的处理方式。**自旋锁不停尝试的好处是什么？

自旋锁用循环去不停地尝试获取锁，让线程始终处于`Runnable`状态，节省了线程状态切换带来的开销。

阻塞和唤醒线程都需要高昂的开销，如果同步代码块中的内容不复杂，那么可能转换线程带来的开销比实际业务代码执行的开销还要大。很多场景下，可能我们的同步代码块的内容并不多，所以需要的执行时间也很短，如果我们仅仅为了这点时间就去切换线程状态，那么其实不如让线程不切换状态，而是让它自旋地尝试获取锁，等待其他线程释放锁，有时我只需要稍等一下，就可以避免上下文切换等开销，提高了效率。

### 12. 生成内存





### 13. 系统调用

系统调用和普通函数调用的区别仅仅在于：系统调用由操作系统核心提供，运行于核心态；而普通的函数调用由函数库/用户自己提供，运行于用户态。

系统调用就是Linux内核中设置的一组用来实现各种系统功能的子程序，用户可以通过系统调用命令在自己的应用程序中调用它们。

凡是和系统级别资源相关的操作，都必须通过系统调用方式向操作系统提出请求，由操作系统来完成，系统调用主要完成以下操作：

- **内存管理**：内存分配、回收，获取作业占用内存区大小和地址
- **进程控制**：创建、销毁、阻塞、唤醒进程
- **文件管理**：创建、删除、读写文件
- **设别管理**：请求、释放、启动设备

### 14. `IPC`

为了提高系统硬件的并行操作能力，引入了进程的概念。各个进程运行在不同的内存空间中，一个进程对某个数据的修改另一个进程是无法感知的，因此需要通过进程间通信来传递信息。并发进程之间相互通信是实现多进程间协作和同步的常用工具。

- **匿名管道**（pipe）
  - 半双工，数据只能单向流动；需要双向通信时，需要建立起两个管道；
  - 具有固定读端和写端，一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；管道能将信息从一个进程的地址空间拷贝到另一个进程的地址空间；
  - 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程)的通信；
  - 可以看成是一种特殊的文件，对于它的读写也可以使用普通的 read 和 write 函数，但它不是普通文件，不属于其他任何文件系统，并且只存在于内存中。
- **命名管道（FIFO）**
  - 可以用于不相关进程之间的通信
  - 是一种先进先出的队列，只允许数据的单向流动
  - 以一种特殊设备文件的形式存在于文件系统中
- **消息队列**
  - 是由消息的链表，存放在内核中
  - 独立于发送和接收进程，进程终止时，消息队列及其内从不会被删除
  - 可以实现消息的随机查村，不一定以先进先出的次序读取
- **信号**
  - 用于通知进程某个事件的发生
- **共享内存**
  - 是最快的通信方式，映射一段能被其他进程所访问的内存，无需复制
  - 内存共享区的互斥要通过信号量等机制来实现
- **信号量**
  - 常作为一种锁机制来实现进程间同步，若要在进程间传递数据需要结合共享内存
  - 是基于操作系统的PV操作，程序对信号量的操作都是原子操作
- **套接字**
  - 与其他通信机制不同的是，它可用于不同计算机间的进程通信

### 15. 虚拟内存管理

- #### **什么是逻辑地址？为什么要有逻辑地址？**

  程序自己看到的地址空间，是抽象的地址，每个进程使用独立的逻辑地址空间，需要映射到实际的物理内存中才能完成对内存的操作，也叫虚拟地址。

  **抽象出来的逻辑地址满足了多进程的要求。**如果没有不抽象出逻辑地址，会有两个问题：

  （1）用户程序可以访问任意内存，多进程同时操作同一块物理内存地址会造成崩溃；

  程序是写死的，操作的地址是固定的；而系统是多任务处理的，内存要同时装入多个程序，物理内存的使用情况是动态变化和不可预知的，当前进程需要的内存可能已经被其他进程所使用了，断然不能被使用了。如果没有虚拟内存，用户程序可以访问任意内存，多个进程操作到的内存区域可能会重复，造成崩溃。

  （2）同时运行多个程序特别困难

  操作系统往往需要多进程执行，所谓多进程，并不需要同时运行这些进程，只要它们都处于`ready`状态，操作系统可以快速地在它们之间切换，就能达到同时运行的假象。而每个进程都需要内存，在上下文切换时，之前的内存中的数据怎么办呢？简单粗暴的方法就是，保存现场时拷贝到磁盘，恢复现场时从磁盘中载入之前保存的数据。但这样太慢了！

  逻辑地址让多个进程不能直接地去操作同一块物理地址，将每个进程的内存隔离开，保证多进程能安全地操作内存。同时利用进程地址空间中的 PCB 保存进程的所有信息，恢复现场很方便。



- #### **什么是虚拟内存？为什么要有虚拟内存？** 

  **每个程序能够独立运行都得益于虚拟内存设计。**

  如果有两个进程，一个需要`2G`，一个需要`3G`，但计算机只有`4G`物理内存，物理内存不够用怎么办？

  虚拟内存是一种技术，不采取一次性兑换的方式，其基本思想是：**将程序暂时不用的页面换出到磁盘上。**
  
  内存是计算机中很重要的资源，程序运行必须要加载到内存中才可以运行，CPU 需要的指令和数据都是来自内存的，但内存的大小非常有限，而多个进程运行时所需要的内存大小却远远不止实际物理内存的大小。为了解决了程序需要内存与实际内存之间的矛盾问题，就引入了虚拟内存。



- #### **分页**

  程序使用的内存是无法计算的，随着时间的推移，进程使用的内存是不断变化的，只能先估算程序最大需要的内存分配给它，这样会导致内存的使用率不高，因为程序运行过程中很多时候用不到这么大的内存，没有利用起来的内存叫做**内碎片**。当程序运行完，它所使用的内存会被释放，如果很长时间内都没有能使用那段内存的进程被创建，那块内存就会被闲置，就成了**外碎片**。**分页的话，一个程序在物理上不必连续存放，可以解决外碎片问题。**

  分页是将逻辑内存和物理内存都进行切分，分程固定大小的片，每一片叫做**页**，在逻辑内存中页叫做`page`，在物理内存中页叫做`page frame`。这样就可以将逻辑内存中的页映射到物理内存中的页上，而这些页在物理内存上的位置就可以不连续了，但进程会以为自己的内存是连续的，因为它看到的只是虚拟内存。这种从逻辑内存的`page`到物理内存的`page frame`的映射关系需要一个表来维系，这个表就叫做**页表（page table）**。页表中存储的关键信息是虚拟内存中的位置信息【页号】，该页是否在物理内存中，如果在，会记录该页在物理内存中的位置信息【帧号】，如果不在，会记录该页在磁盘中的位置信息。页表是每个进程都有一个页表需要维护。

  ![image-20210831140645452](https://i.loli.net/2021/08/31/s46yMoWNkE2GnfQ.png)

  进程访问数据时会通过页表进行地址映射找到数据在内存中的位置。首先查找 `MMU` 存放的快表中有无当前进程的页表（快表的命中率很高），如果没有再去内存中查找；找到页表后，查看要访问的页是否在内存中，如果在，就去给的内存位置信息找到该页，如果不在，就去磁盘中找到该页，如果内存满了要使用页面置换算法，淘汰掉内存中最久没有访问的页，将磁盘中的页放进内存中。

  **分页的意义是什么？**

  （1）一个逻辑地址可以映射到一个 `4KB` 大小的物理内存块上，这样就使得程序可以使用的内存空间变大；

  （2）分页实现了进程之间的物理内存的隔离，保证了安全；只要帧号不冲突就是安全的；

  （3）分页降低了内存碎片的问题；

  缺点：但分页过程中，需要两次读内存（一次读页表，一次找帧），时间上有待优化，页表存在内存中，占用空间较大，空间上也有待优化。

  时间上的优化：使用快表，快表在CPU中，读CPU比读内存快得多，快表命中率很高，很大程度上提升了速度。

  空间上的优化：多级页表。

  

- #### **缺页中断**

  如果在内存寻址过程中，该页在页表中对应的帧号是磁盘，就会发生缺页中断。

  缺页中断会触发程序进入内核态，内核会在磁盘中找到这一页数据将其加载到物理内存中，然后将在物理内存中的帧号填写到页表中，重新进行一个刚刚进行的内存寻址的过程。

  如果内存满了，就使用页面置换算法，将最久没有使用的帧逐出到磁盘，为访问的页腾出位置。

  

- #### **内存寻址的过程**

  机器：32位系统，`256 MB`内存（`256 MB = 2^8 * 2^20 B= 2^28 B`）

  程序：32位程序

  页大小为`4 KB = 4 * 2^10 B= 2^12 B` ，需要用`12`位地址来表示。一个页中有`2^12`个最小的内存单元，如果要找到最小内存单元在页中的哪个位置，就需要用12位地址来表示每个最小单元在页内的偏移量。

  逻辑地址：32 bit = 20 bit 页号 + 12 bit 页内偏移，也就是说虚拟内存可以分为`2^20`个页（page）

  物理地址：28 bit = 16 bit 帧号 + 12 bit 页内偏移，也就是说物理内存可以分为`2^16`个帧（page frame）

  页号 —— 指示位于第几个页，页内偏移 —— 指示最小内存单元在页中的什么位置

  如果要访问一个逻辑地址为`0x000011a3`的空间，它在物理内存中的什么位置？

  将逻辑地址分为两半，前面 20 bit `00001（十六进制）`代表页号，后面 12 bit `1a3 `代表页内偏移

  ![image-20210831151239662](https://i.loli.net/2021/08/31/ZR3ycCf9lbGXxW6.png)



- #### 程序内部的内存管理

  从进程的角度看，内存的布局是这样的：（只是进程以为的，在实际物理内存中不是这样）

  ![image-20210901105110614](https://i.loli.net/2021/09/01/KDJUAChYg51cByN.png)

  栈和堆中间有一块 `free space`，即使没有用，也被占着。

  **分段管理**：将进程的虚拟空间分成四个内存区域，也就是分段（代码段、数据段、堆、栈），每个段的逻辑地址都是从`0`开始的，每个段里面有很多页，页表中存储段号和页号唯一映射物理帧号。

  **分段的意义是什么？**

  不同区域存放的数据，赋予不同的生命周期，给与更大的灵活编程。

  因为段页结合的模式只在 x86 Intel CPU 等少数 CPU 上还支持，更新的 x86-64 架构都不再支持段页结合了。也就是说分段并不会在实际的内存管理中发挥作用了，只是保留了程序层面上的逻辑概念。

  `Text`——存储程序字节码

  `Data`——存储程序中的静态变量

  `堆`——用户动态申请的内存，`malloc()`申请空间时，如果申请大小`< 128 KB`，调用`brk()`在这开辟内存。

  共享映射区——存放程序使用的动态链接库，这里是进程共享的。（当用`malloc()`申请空间时，如果申请的大小`> 128KB`，就会调用`mmap`在这块区域开辟一块空间）

  `栈`——存放函数中的局部变量，形参，返回值

  

- #### 页式 vs段式

  相同之处在于：两者都采用离散分配方式，且都通过地址映射机构来实现地址变换。但概念上两者也有很多区别，主要表现在：

  - 需求

    是信息的物理单位，分页是为了实现离散分配方式，以减少内存的碎片，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了更好地满足用户的需要。一条指令或一个操作数可能会跨越两个页的分界处，而不会跨越两个段的分界处。

  - 大小

    页大小固定且由系统决定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的。段的长度不固定，且决定于用户所编写的程序，通常由编译系统在对源程序进行编译时根据信息的性质来划分。

  - 逻辑地址表示

    页式系统地址空间是一维的，即单一的线性地址空间，程序员只需利用一个标识符，即可表示一个地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。

  - 速度

    段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。



### 16. 物理内存管理

金字塔存储结构：

<img src="https://i.loli.net/2021/09/01/JtprPSQwoHaCMAi.png" alt="image-20210901103353699" style="zoom:80%;" />

计算机由 CPU 、内存、外部设备组成，它们之间通过总线连接在一起。CPU 负责数据处理，内存负责存储，外部设备负责数据的输入输出。CPU内部由控制器、运算器和寄存器组成。控制器负责指令的读取和调度，运算器负责指令的运行，寄存器负责数据的存储。

<img src="https://i.loli.net/2021/09/01/6aH7rApDuzFQCw9.png" alt="image-20210901103637315" style="zoom:80%;" />

设计思想：冯诺依曼体系架构，一部分负责调度控制，一部分负责执行，一部分负责数据存储，它们之间进行交互以及接口通信总是通过总线来完成。这种设计思路一样可以应用到软件设计系统中，组件与组件之间通信通过事件的方式来进行解耦处理，组件内部明确自己部分的职责。

**单位换算**

`1 Byte = 8 bit`

`1 KB = 1024 Bytes = 2^10 Bytes`

`1 MB = 1024 KB = 2^20 Bytes`

` 1 GB = 1024 MB = 2^30 Bytes`

`1 页 = 4 KB = 4096 Bytes`

内存的一个地址里面放1个字节（`Byte`）的数据。

32位操作系统中，32位可以表示`2^32`个的物理地址，每个地址可以放1字节的数据，因此总共可以放`2^32`（ `Byte`）的数据，`2^32 B = 2^30 B * 4 = 1 GB * 4 = 4 GB`。

任何一个32位的程序可操作的逻辑地址是`2^32`个，即`4GB`，每个程序都天真地以为自己拥有`4GB`内存。

这势必会造成多个程序使用内存的总和大于物理内存，此时会借助磁盘。



**Linux内核内存管理的一项重要工作就是如何在频繁申请释放内存的情况下，避免碎片的产生。Linux采用伙伴系统解决外部碎片的问题，采用slab解决内部碎片的问题。**

- **√√ 伙伴系统**

  **Linux 操作系统主要的内存分配算法是伙伴系统，机制是按照2的幂次方进行分块，然后根据需求分配差不多的内存块给使用者，伙伴系统是一个结合了2的方幂个分配器和空闲缓冲区合并计技术的内存分配方案。分配和释放机制十分强大。**

  不过缺点是会分配多余的空间，释放的时候是释放相邻的大小相同的内存块，如果中间有一个小碎片，那么就不能合并，针对这种情况，提出了一种辅助算法**slab算法**。机制：其工作是**针对一些经常分配并释放的对象**，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。

  

- **伙伴系统与 slab 机制**

  在实际应用中，经常需要分配一组连续的页框，而频繁地申请和释放不同大小的连续页框，必然导致在已分配页框的内存块中分散了许多小块的空闲页框。这样，即使这些页框是空闲的，其他需要分配连续页框的应用也很难得到满足。

  为了避免出现这种情况，`Linux`内核中引入了伙伴系统算法(`buddy system`)。把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。最大可以申请1024个连续页框，对应`4MB`大小的连续内存。每个页框块的第一个页框的物理地址是该块大小的整数倍。

  假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。

   页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。 

  **Buddy算法的优缺点：**

  　　1）尽管伙伴内存算法在内存碎片问题上已经做的相当出色，但是该算法中，一个很小的块往往会阻碍一个大块的合并，一个系统中，对内存块的分配，大小是随机的，一片内存中仅一个小的内存块没有释放，旁边两个大的就不能合并。

  ​		2）**存在内部碎片**，伙伴算法是按2的幂次方大小进行分配内存块，当然这样做是有原因的，即为了避免把大的内存块拆的太碎，更重要的是使分配和释放过程迅速。但是他也带来了不利的一面，如果所需内存大小不是2的幂次方，就会有部分页面浪费。有时还很严重。比如原来是1024个块，申请了16个块，再申请600个块就申请不到了，因为已经被分割了。

  　　3）另外拆分和合并涉及到较多的链表和位图操作，开销还是比较大的。

  **满足以下三个条件的称为伙伴：**
  　　1）两个块大小相同；
  　　2）两个块地址连续；
  　　3）两个块必须是同一个大块中分离出来的；

  **Buddy算法的分配原理：**

  假如系统需要`4(2*2)`个页面大小的内存块，该算法就到`free_area[2]`中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找`free_area[3]`,如果`free_area[3]`中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入`free_area[2]`，后四个页面分配出去，`free_area[3]`中也没有，就再向上查找，如果`free_area[4]中`有，就将这`16(2*2*2*2)`个页面等分成两份，前一半挂如`free_area[3]`的链表头部，后一半的`8`个页等分成两等分，前一半挂`free_area[2]`的链表中，后一半分配出去。假如`free_area[4]`也没有，则重复上面的过程，知道到达`free_area`数组的最后，如果还没有则放弃分配。（链表的头部用红黑树来存储？）

  ![image-20210901142443020](https://i.loli.net/2021/09/01/9ND3ZTr6sUKb1p2.png)

   **Buddy算法的释放原理：**

  内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块(2*2*2*2*2*2*2*2*2个页面)。 

  **slab机制**

  `slab`是`Linux`操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而`slab`分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，`slab`分配器就从一个`slab`列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。`slab`分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。 

  `Linux` 的`slab `可有三种状态：（维护三个链表）
   　满的：`slab `中的所有对象被标记为使用。
   　空的：`slab `中的所有对象被标记为空闲。
   　部分：`slab` 中的对象有的被标记为使用，有的被标记为空闲。
  `slab` 分配器首先从部分空闲的`slab` 进行分配。如没有，则从空的`slab` 进行分配。如没有，则从物理连续页上分配新的`slab`，并把它赋给一个`cache` ，然后再从新`slab` 分配空间。

  与传统的内存管理模式相比， `slab` 缓存分配器提供了很多优点。
  　　1、内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。
  　　2、`slab` 缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。
  　　3、`slab` 分配器还支持通用对象的初始化，从而避免了为同一目的而对一个对象重复进行初始化。
  　　4、`slab` 分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。

  因为`slab`要维护三个链表，开销比较大，所以出现了它的优化算法`slub`，只用维护1个链表，每个节点标记状态。

### 17. 内存碎片

避免外部碎片的方法有两种：
（1）是利用分页单元把一组非连续的空闲页框映射到连续的线性地址区间；
（2）伙伴系统：是记录现存空闲连续页框块情况，以尽量避免为了满足对小块的请求而分割大的连续空闲块。

**伙伴系统（解决外部碎片）**
使用场景：内核中很多时候要求分配连续页，为快速检测内存中的连续区域，内核采用了一种技术：伙伴系统。
原理：系统中的空闲内存总是两两分组，每组中的两个内存块称作伙伴。伙伴的分配可以是彼此独立的。但如果两个小伙伴都是空闲的，内核将其合并为一个更大的内存块，作为下一层次上某个内存块的伙伴。

**伙伴系统的缺点：由于分配的都是2的幂次方的内存，会有内部碎片。**

**slab分配（分配小对象，小于一个页框），解决内部碎片问题**

### 18. 页面置换算法 

- **页面置换算法是用来解决什么问题的？**

  在虚拟内存映射到物理内存的过程中，如果去页表中查看后发现要访问的页不在内存中，就会产生**缺页中断**。当发生缺页中断时，如果物理内存中没有空闲的页，系统就必须在内存中选择一个页面将其移出内存，以便为即将从调入的页腾出空间。而用来**选择淘汰哪一页的规则**就叫做页面置换算法。

- #### **`LRU`**

  最近最少使用置换算法，淘汰最久未使用的。可以用一个双向链表和一个哈希表来实现。

- **缓存命中（cache hit）**

  当应用程序或软件请求数据时，CPU 在其最近的内存位置（主缓存）中查找数据，**如果在缓存中找到了请求的数据，则将其视为缓存命中**。

- **`LRU`例题**

  某缓存系统采用`LRU`淘汰算法，假定缓存容量为 4，并且初始为空，那么在顺序访问以下数据项的时候，1、5、1、3、5、2、4、1、2，出现**缓存直接命中**的次数是（），最后缓存中即将准备淘汰的数据项是（）

  - 访问的数据项如果在缓存中找不到，就直接放到最前面，同时旧数据往后挪
  - 访问的数据项如果在缓存中能找到，就将该数据项从原来的位置更新到最前面，同时旧数据往后挪
  - 如果缓存满了，就踢掉最后的数据项

  <img src="https://i.loli.net/2021/08/30/fRDI6QyWgsGiLht.png" alt="image-20210830221955720" style="zoom:80%;" />

- #### `LFU`

  最少使用置换算法，记录下每个页面被访问的**频率**，淘汰访问频率最低的，对于同频率的就淘汰先进去的。

  可以用两个哈希表和多个双向链表来实现，一个哈希表用来找到具体在哪个链表（找到链表头部），一个哈希表用来找到具体在链表的哪个位置；每个链表中存放访问频率相同的数据项。

- #### `FIFO`

  先进先出置换算法，相当于一个普通队列。

### 19. 文件访问权限

Linux 文件权限一般以八进制表示，格式为 abc 的形式，其中 a、b、c 各为一个数字，分别表示 User、Group、Other 对该文件的操作权限。

第一位表示文件所有者User拥有的权限

第二位表示文件所有者同组用户Group拥有的权限

第三位表示公共用户Other 拥有的权限

具体权限由数字来表示，可读权限等于4，可写权限为2，可执行权限为1。7=4+2+1表示可读可写可执行，6=4+2表示可读可写，5=4+1表示可读可执行。

### 20. Linux 命令

#### (1) top 命令

Linux 下常用的性能分析工具，能实时显示系统中进程的资源占用情况，类似于 Windows 下的任务管理器。

**第一行，任务队列信息，同 uptime 命令的执行结果**

> 负载均衡(uptime) load average: 0.00, 0.00, 0.00
>
> average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。
>
> load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了

**第二行，Tasks — 任务（进程）**

**第三行，cpu 状态信息**

**第四行，内存状态**

**第五行，swap交换分区信息**

**第六行，空行**

**第七行以下：各进程（任务）的状态监控**

## 六. 计算机网络

### 1. 分层模型

为什么要分层？

（1）各层之间相互独立，上层无需关心底层的实现，只需要知道底层接口就可以获得所需服务

（2）灵活性好，某一层的实现技术的改变不会影响其他层

（3）易于实现和标准化，由于采取了规范的层次结构去组织网络功能与协议，因此可以将计算机网络复杂的通信过程，划分为有序的连续动作与有序的交互过程，有利于将网络复杂的通信工作过程化解为一系列可以控制和实现的功能模块，使得复杂的计算机网络系统变得易于设计，实现和标准化

<img src="https://i.loli.net/2021/08/30/dqjylCXmcOUL9vH.png" alt="img" style="zoom:67%;" />

应用层：HTTP、FTP、`POP3`、SMTP、`DNS`

传输层：TCP、`UDP`

网络层：`IP`协议，绑定`IP` 地址和端口，将用户数据准确地发出去（路由器）

数据链路层：连接硬件设备程序，如网卡驱动（交换机）

物理层：硬件本身

**路由器、交换机位于哪一层？**

路由器网络层，根据IP地址进行寻址；交换机数据链路层，根据MAC地址进行寻址。

### 2. **HTTP 描述**

- [ ] **HTTP 响应状态码**

  - 200 - 请求成功
  - 301 - 资源被永久转移到其他 URL
  - 404 - 请求资源不存在
  - 500 - 内部服务器错误

- [ ] **HTTPS 怎样保证数据安全**

  HTTPS 是 HTTP 和 SSL 协议组成的安全协议。它保证了三点：

  - 数据内容加密（对称加密技术）
  - 数据完整性保护（数据摘要、数字签名-保证不被篡改）
  - 身份认证（数字证书）

  HTTPS 能保证安全性的原因：

  - 握手阶段：使用非对称加密技术对公钥进行加密
  - 传输阶段：使用对称加密技术对报文进行加密

- [ ] **HTTP可以指定传输内容的类型**

- [ ] **HTTP协议是无状态的**

- ### **HTTP 无状态**

  HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，每个请求都是完全独立的。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接。

  无状态协议的缺点是：单个请求需要的所有信息不能分多次发送到服务端，只能将所有信息包含在请求中一次发送，这会导致单个消息的结构比较复杂，因此HTTP消息的解析要比其他协议复杂。同时，也会导致相同的数据在多个请求上往往需要反复传输。

- ### HTTP 长连接和短连接

  HTTP协议的长连接和短连接实质上是TCP协议的长连接和短连接。

  **短连接：**客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

  ```http
  Connection:close
  ```

  **长连接：**当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问该服务器时，会继续使用这一条已经建立的连接。长连接不会永久保持连接，它有一个保持时间，可以在不同的服务器软件中设定这个时间。

  ```HTTP
  Connection:keep-alive
  ```

  长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，比如数据库的连接，适合用长连接。Web网站的HTTP服务一般用短连接，因为每个用户一般都不会频繁操作，长连接对于服务端来说会耗费一定资源，而Web网站这样频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源。在长连接的应用场景下，客户端一般不会主动关闭它们之间的连接，客户端和服务器之间的连接如果一直不关闭，随着客户端连接越来越多，服务器早晚扛不住，此时服务端需要采取一些策略，如关闭一些长时间没有读写时间发生的连接。

- ### `HTTP 1.0` vs `HTTP 1.1`

  1.0 规定浏览器与服务器之保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户，也不记录过去的请求。

  1.1 支持长连接。在同一个TCP连接中可以进行多次HTTP请求和响应。提供更多的请求头和响应头（比如1.0没有的host字段，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；为close时，返回本次请求结果后关闭连接；此外还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头）

### 4. HTTP 报文 状态码

**报文**

- 请求报文包括：请求行、请求头部、空行和请求数据

  请求行：用于说明请求类型（GET/POST），要访问的资源（URL）以及使用的HTTP版本（`HTTP1.1`）

- 响应报文包括：状态行、消息报头、空行、响应正文

  状态行：HTTP协议版本号（`HTTP1.1`）、状态码（200）、状态消息（OK）

**状态码**

<img src="https://i.loli.net/2021/08/26/VewAURPO258aIpn.png" alt="image-20210826203358722" style="zoom: 50%;" />

### 5. 打开网页的过程

![image-20210923093751652](https://i.loli.net/2021/09/23/JDTIjYxp4wQfkLM.png)

**网页打不开，如何排查问题？**

![image-20210831160557231](https://i.loli.net/2021/08/31/QGm1Ilhijq7DXUP.png)

### 6. `HTTPS`的`SSL`连接过程

SSL（安全套接字层协议），在传输层与应用层之间对网络连接进行加密。密钥的传输使用了非对称加密，而数据的传输使用了对称加密。

![](https://i.loli.net/2021/08/09/P62xfrEFulaAZKB.jpg)

<img src="https://i.loli.net/2021/08/09/3Jqv2sgI8xKzAPZ.png" alt="image-20210809204132668" style="zoom: 50%;" />

<img src="https://i.loli.net/2021/08/09/Ps5efb9kXF8hjWq.png" alt="image-20210809203246652"  />

- 服务器用CA证书证明自己的身份，客户端用CA发行的公钥验证证书的有效性

  别人无法冒充服务器，因为服务器的CA数字证书是服务器公钥的数字签名，是CA用自己的私钥签的名，用CA的公钥可以验签，因此第三方无法篡改数字证书来冒充服务器的身份

- 服务器用CA的私钥加密自己的公钥，客户端用CA发行的公钥解密服务器的公钥（服务器的公钥人人都能获取到）

- 客户端用服务器的公钥加密自己随机生成的公钥，服务器用自己的私钥破解出客户端发来的公钥，这个公钥只有客户端和服务器知道，它们就能通过这把钥匙加密/解密所有信息了

### 7. `GET` vs `POST`

GET和POST是HTTP协议中的两种请求方式，HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。

- GET 是用于请求从服务器获取资源，POST  是相反的操作，向 URI 指定的资源提交数据，数据就放在报文的 body 中。GET 是只读的，是幂等安全的，POST 不是幂等安全的。

- **直观区别（不是面试官想要的答案）**

  HTTP底层是TCP/IP，所以GET和POST的第层也是TCP/IP，也就是说GET/POST都是TCP连接，GET和POST能做的事情是一样的，要给GET加上请求体，给POST带上URL参数，技术上是完全行得通的。但是由于HTTP的规定和浏览器/服务器的限制，导致它们在应用过程中呈现出以下不同：

  - GET将参数包含在URL中，POST通过请求体传递参数；
  - GET请求参数会被完整保留在浏览器历史记录中，而POST中的参数不会被保留
  - GET请求在URL中传送的参数是有长度限制的，POST没有

- **本质区别**

  **GET产生一个TCP数据包；POST产生两个TCP数据包**

  （GET只需要一趟就能将货送到，而POST得跑两趟，第一趟先去和服务器大哥招呼说它要送货来了，然后再回头将货送过去）

  对于GET请求，浏览器会将http header和data一并发送出去，服务器响应200（返回数据）

  对于POST请求，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）

  ![image-20210809215659975](https://i.loli.net/2021/08/30/Dtba28I9KB7nGUk.png)

### 8. **子网划分**

与`10.110.12.29` mask `255.255.255.240`处于同一网段的 IP 是？

- [x] 10.110.12.17
- [ ] 10.110.12.31
- [x] 10.110.12.30
- [ ] 10.110.12.0

240 = 128 + 64 + 32 + 16 = 1111 0000，也就是说第四个字节有四位用来表示子网号。10.110.12.29 = 10.110. 12. 0001 1101，所以跟这个 IP 处于同网段的 IP 的前 28 位是固定的网络标识：10.110.12. 0001 xxxx，最后 4 位是主机标识，可以是 **0001 ~ 1110**（注意：全 0 和全 1 不行）。0001 0001 ~ 0001 1110 也就是 17 ~ 30。

广播地址是主机号全为1，也就是 10.110.12.31

### 9. `TCP` vs `UDP`

TCP是一个可靠传输的协议，考虑到了数据破坏、丢包、重复以及分片顺序混乱等问题。它是如何保证可靠的呢？是通过序列号、确认应答、重发控制、连接管理及窗口控制等机制来实现的。

![image-20210827234819313](https://i.loli.net/2021/08/27/1WFV6aAwhY4QOnS.png)

### 10. TCP 重传机制

TCP 实现可靠传输的方式之一是通过序列号和确认应答。在TCP中当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已经收到消息。

- **重传机制是为了解决什么问题？**

  在错综复杂的网络中，数据在传输过程中可能会丢失。重传机制是为了解决数据包丢失的情况。

- **重传机制有哪些？**

  - **超时重传**

    发送方发送数据时设定一个定时器，如果定时器超时了，还未收到接收方的 `ACK` 确认应答报文，发送方就会重发该数据。

    TCP 会在以下两种情况下发生超时重传：（1）数据包丢失；（2）确认应答丢失。这两种情况都会导致发送方收不到接收方的 `ACK` 确认应答报文。

    **超时时间应该设置为多少？**

    超时重传时间 RTO 略大于报文往返 RTT 的值。实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。

    如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

    超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？于是就可以用「快速重传」机制来解决超时重发的时间等待。

  - **快速重传**

    TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。

    <img src="https://i.loli.net/2021/08/28/ZcrpILK91XV4Oka.png" alt="image-20210828004203425" style="zoom: 67%;" />

    在上图，发送方发出了 1，2，3，4，5 份数据：

    - 第一份 Seq1 先送到了，于是就 Ack 回 2；
    - 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
    - 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
    - **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
    - 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

    所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

    快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传所有的问题。**

    比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。

    根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。

    为了解决不知道该重传哪些 TCP 报文，于是就有 `SACK` 方法。

  - **SACK（选择性确认）**

    这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

    如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。

    ![image-20210828004842402](https://i.loli.net/2021/08/28/svTEPGZWXkQH9Aj.png)

  - **D-SACK**

    Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

    <img src="https://i.loli.net/2021/08/28/Cc1kt76OzXeJbL3.png" alt="image-20210828004946312" style="zoom: 67%;" />

    - 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
    - **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
    - 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

    <img src="https://i.loli.net/2021/08/28/PbOmwcYGKSejTJr.png" alt="image-20210828005340217" style="zoom: 80%;" />

    - 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
    - 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
    - **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
    - 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

    可见，`D-SACK` 有这么几个好处：

    1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
    2. 可以知道是不是「发送方」的数据包被网络延迟了;
    3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 11. TCP 滑动窗口

- **为了解决什么问题？**

  因为TCP每发送一个数据都要进行一次确认应答，只有当上一个数据收到应答了，再去发送下一个。这样的传输方式有一个缺点：数据包的往返时间越长，通信的效率就越低。因此引入窗口的概念，可以指定窗口大小，**窗口大小是指无需等待确认应答，可以连续发送数据的最大值**。

  <img src="https://i.loli.net/2021/08/28/PvOLfGrqlKUAzmN.png" alt="image-20210828005740961" style="zoom: 67%;" />

- **窗口是什么？**

  窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回前，必须在缓冲区中保留已发送的数据，如果按期收到确认应答，此时数据就可以从缓存区清除。

  TCP头中有一个字段叫Window，也就是窗口大小，该字段是接收端告诉发送端自己还有多少缓存可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

- **窗口的大小由谁决定？**

  窗口大小是由接收方的窗口大小来决定。发送方发送的数据不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。接收窗口和发送窗口的大小不完全相等，但约等于。因为滑动窗口并不是一成不变的。比如当接收方的应用进程读取数据的速度很快，这样的话接收窗口就可以很快地腾出位置来。那么新的接收窗口大小，是通过TCP报文中的Windows字段来告诉发送方。那么这个传输过程是存在延时的，在此期间，接收窗口和发送窗口可能不一样。

- **操作系统缓冲区与滑动窗口的关系**

  实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响，所以**发生窗口和接收窗口并非不变的**。

  如果接收端收到数据后，应用程序没有及时地读取数据，数据会留在接收缓冲区，接收窗口就会缩小，接收方会在发送确认消息时告知发送方窗口的大小，发送方收到确认消息后也会随之调整发送窗口大小。

  如果系统资源非常紧张，操作系统可能会直接减少接收缓冲区的大小，此时如果应用程序无法及时读取缓存数据，接收缓冲区不足以存放发送方发来的数据，便会引发数据丢包。

  **为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**

![image-20210827210454793](https://i.loli.net/2021/08/27/HQhwi2zPkJLUAeB.png)

![image-20210827210840077](https://i.loli.net/2021/08/27/pu8iwzQPkSUE12M.png)

![image-20210827211247006](https://i.loli.net/2021/08/27/uW8rH9SdTXBaONl.png)

![image-20210827211326637](https://i.loli.net/2021/08/27/MEaKDQCIsUmwJ21.png)

### 12. TCP 流量控制

- **什么是流量控制？**

  发送方不能无脑地发送数据给接收方，要考虑对方的处理能力。如果一直无脑地发数据给对方，但对方处理不过来，就会触发重发机制，导致网络流量的无端浪费。为了解决该问题，**TCP提供一种机制可以让【发送方】根据【接收方】的实际接收能力控制发送的数据量，让接收方告诉发送方自己能够接收的数据大小（窗口大小），这就是流量控制。**

- **如何实现流量控制？**

  由滑动窗口协议实现。接收窗口指示发送方——接收方还有多少可用的缓存空间。因为TCP是全双工通信，在连接两端的发送方都各自维护了一个接收窗口。

- **窗口关闭潜在的危险——死锁？如何避免？**

  **如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

  接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。那么，当发生窗口关闭时，接收方处理完数据后，接收缓冲区空出来了，窗口增大了，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。

  这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

  ![image-20210828012208220](https://i.loli.net/2021/08/28/KlUy4bV5PkY3jCf.png)

  为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

  如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

  ![image-20210828012427348](https://i.loli.net/2021/08/28/MYg3aqkvdbZUSTf.png)

  - 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
  - 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

  窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

- **糊涂窗口综合征**

  如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

  到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

  要知道，我们的 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家里有矿的大巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。

  糊涂窗口综合症的现象是可以发生在发送方和接收方：

  - 接收方可以通告一个小的窗口
  - 而发送方可以发送小数据

  于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

  - 让接收方不通告小窗口给发送方
  - 让发送方避免发送小数据

  **接收方通常的策略**如下:

  当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

  **发送方通常的策略:**

  使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

  - 要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`
  - 收到之前发送数据的 `ack` 回包

  只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。

### 13. TCP 拥塞控制

- **为什么要有拥塞控制，不是有流量控制了吗？**

  流量控制是避免发送方的数据填满接收方的缓存，但是不知道网络中发生了什么。一般而言，计算机网络都处于一个共享的环境，可能会因为其他主机之间的通信使得网络拥堵。**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢包等，此时TCP就会重传数据，但是一重传就会导致网络负担的加重，于是会导致更大的延迟以及更多的丢包，这种情况会进入恶性循环。- - - - 于是。当网络拥塞时，TCP会自我牺牲，降低发送的数据量。**

  流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送方维持一个叫做拥塞窗口的状态变量，**拥塞窗口的大小取决于网络的拥塞程度，并且动态地变化。**

- **拥塞窗口变化规则：**

  （1）只要网络中没有出现拥塞，拥塞窗口就会增大；

  （2）但网络中出现了拥塞，拥塞窗口就会减小。

- **怎么知道当前网络是否出现了拥塞？**

  只要发送方没有在规定时间内接收到ACK应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。

- **拥塞控制主要涉及到四个算法：**

  - 慢启动

  - 拥塞避免

  - 拥塞发生

  - 快速恢复

    

- **慢启动（指数性增长）**

  TCP刚建立连接，将发送方的拥塞窗口设定为1，之后每次收到确认应答，将拥塞窗口大小 x 2。

  慢启动算法的思路是：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，指数规律地增加拥塞窗口的大小。

  慢启动涨到何时是个头？有一个**慢启动门限**状态变量（一般是`65535`字节），当拥塞窗口大小达到门限前使用慢启动算法；达到门限后使用拥塞避免算法。

  <img src="https://i.loli.net/2021/08/27/EuwCZeGJKXj6b25.png" alt="image-20210827213639113" style="zoom:80%;" />

  

- **拥塞避免（线性增长）**

  当拥塞窗口大小达到慢启动门限，拥塞窗口大小就不再指数上升，而是加法增加（每次收到一个`ACK`时，拥塞窗口大小 `+1`），以此来避免拥塞。

  <img src="https://i.loli.net/2021/08/27/GVLomUT3BbWJ7dI.png" alt="image-20210827213713218" style="zoom:80%;" />

  

- **拥塞发生**

  随着拥塞窗口一直在增长，网络就会慢慢进入拥塞状况，于是就会出现丢包现象，此时就需要对丢包的数据进行重传，当触发了重传机制，就进入了拥塞发生算法。

  当网络出现拥塞，就会发生数据包重传，**重传机制有两种：超时重传和快速重传**。这两种使用的拥塞发生机制算法是不同的。

  **（1）发生超时重传的拥塞发生算法**

  当发生**超时重传**时，会发生拥塞发生算法，此时**慢启动门限变为发生拥塞时的拥塞窗口大小的一半，拥塞窗口大小重置为1。并且重新开始慢启动**。

  （慢启动是会突然减少数据流，所以一旦发生超时重传，马上回到解放前，这种方式反应很强烈，会造成网络卡顿）

  <img src="https://i.loli.net/2021/08/27/si6SX3azWn8oZBv.png" alt="image-20210827214523878" style="zoom:80%;" />

  **（2）发生快速重传的拥塞发生算法**

  比起上一种方式，还有更好的方式，也就是**快速重传算法**。当接收方发现丢了一个中间包时，**发送三次前一个包的`ACK`**，于是接收方就会快速地重传，不必等待超时再重传。

  TCP认为这种情况不严重，因为大部分没丢，只丢了一小部分，**拥塞窗口大小设置为原来的一半，慢启动门限设为更新后的拥塞窗口大小，进入快速恢复算法。**



- **快恢复**

  快速重传和快速恢复算法一般同时使用，快速恢复算法认为，你还能收到 3 个重复 `ACK` 说明网络也不是那么糟糕，所以没有必要一下把拥塞窗口重置。

  进入快速恢复前，拥塞窗口和慢启动门限已经被更新了。拥塞窗口更新为原来的一般，慢启动门限更新为更新后的拥塞窗口大小。

  然后，进入快速恢复算法如下：

  - 拥塞窗口 = 慢启动门限 + 3（3 的意思是确认有 3 个数据包被收到了）

  - 重传丢失的数据包

  - 如果再收到重复的 `ACK`，那么拥塞窗口 + 1

  - 如果收到新数据的 `ACK`后，将拥塞窗口设置为第一步中的慢启动门限的值，原因是该 `ACK`确认了新的数据，说明重复的 `ACK`对应的数据已经被收到了，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态 

    （不会像超时重传那样一夜回到解放前，还是再比较高的值）

  ![image-20210827220108446](https://i.loli.net/2021/08/27/Txp6acoHqBUS9X3.png)

### 14. TCP 三次握手

<img src="https://i.loli.net/2021/08/18/SA71g62QEelFhZt.png" alt="image-20210818235420969"  />

**为什么要三次握手？**

首先，可能会出现**已失效的连接请求报文段又传到了服务器端**。

> client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。

其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。

### 15. TCP 四次挥手

![四次挥手](https://github.com/wolverinn/Waking-Up/raw/master/_v_images/20191129112652915_15481.png)

- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；
- 第二次挥手：Server收到FIN之后，发送一个`ACK=1`，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。
- 第三次挥手：Server将FIN置1，发送一个序列号给Client；进入`LAST_ACK`状态；
- 第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将`ACK`置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待`2*MSL`（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。

- **为什么要四次挥手？**

  因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复`ACK`，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

- **如果第二次挥手时服务器的`ACK`没有送达客户端，会怎样？**

  客户端没有收到`ACK`确认，会重新发送FIN请求。

- **客户端TIME_WAIT状态的意义是什么？**

  第四次挥手时，客户端发送给服务器的`ACK`有可能丢失，`TIME_WAIT`状态就是用来重发可能丢失的`ACK`报文。如果`Server`没有收到`ACK`，就会重发`FIN`，如果`Client`在`2*MSL`的时间内收到了`FIN`，就会重新发送`ACK`并再次等待`2MSL`，防止`Server`没有收到`ACK`而不断重发`FIN`。

  `MSL(Maximum Segment Lifetime)`，指一个片段在网络中最大的存活时间，`2MSL`就是一个发送和一个回复所需的最大时间。如果直到`2MSL`，`Client`都没有再次收到`FIN`，那么`Client`推断`ACK`已经被成功接收，则结束`TCP`连接。

### 16. TCP 和 socket 的关系

TCP 是一个协议，是传输层的一种运行机制，而 socket 是操作系统为程序员操作【网络协议栈】的接口，通过 socket 接口来控制协议栈工作，从而实现网络通信。socket 的引入是为了实现跨计算机的进程之间的通信。

### 17. linux 检查网络命令

- ping + IP 地址/域名：测试 IP 是否通
- telnent + IP地址 + 端口号：检查一个地址的某个端口是否可以连通
- curl ：是一个向服务器传输数据的工具，支持 HTTP、HTTPS、FTP、TELNET等，默认GET请求
- wget：是下载文件的命令，能下载就表示能连通

## 七. `STL` 数据结构

`STL`资料网址：https://www.kancloud.cn/digest/mystl/192550

### 1. 排序算法

- [ ] 稳定性

  稳定的算法在排序过程中不会改变元素彼此的位置的相对次序，不稳定的算法会改变这个次序。选择排序算法时，希望次序不会改变，更加稳定。

- [ ] 排序算法总结

  ![preview](https://i.loli.net/2021/08/18/6yQePOgWka358YZ.png)

  其中，**归并排序、堆排序**的时间复杂度在最坏的情况下也不会超过`O(nlogn)`，归并排序是稳定的。

  

**`STL`中的`sort()`系列算法**

前提是容器的迭代器必须为随机迭代器，所以`vector`和`deque`天然适用。`STL`中的`sort`算法使用了一些策略，在不同的情况下采用不同的排序算法，以达到各种算法互补的效果。基本的原则是：数据量大的采用快速排序，数据量小的采用插入排序（这是对快排常用的一种优化策略），递归层次太深改用堆排序。

### 2. map 哈希

内部实现：

- map 内部实现了一个**红黑树**，该结构具有根据 **自动排序**的功能，因此 map 内部的所有元素都是有序的，红黑树的每个节点都代表着 map 的一个元素，因此对于 map 进行的查找、删除和添加的时间复杂度为`O(logn)`

  红黑树是一种特殊的二叉查找树，这里是按照 **key** 来排序。

- unordered_map内部实现了一个**哈希表**，因此其元素的排列顺序是**杂乱无序**的。

![image-20210827151905428](https://i.loli.net/2021/08/27/KTOLjQaB4xo9wRG.png)



**unordered_map 的扩容方式**

hash 增长规律应该是每次成长到**不小于当前桶大小两倍的最小素数**，因为**哈希表的大小是素数时冲突的概率最小**，如果直接扩大为两倍性能反而可能恶化。随着容量的增大，素数的密度会下降得足够小，也不至于反复扩容。



**什么是哈希冲突**

两个不同的数经过哈希函数计算后得到同一个结果，它们会被映射到哈希表的同一位置，这种情况就叫哈希冲突。解决哈希冲突的方法有：**链接法**和**开放寻址法**。

- **链接法**

  源于链表的启发，将被哈希到哈希表同一位置的数通过链表进程链接，使它们能够在哈希表中共存，从而解决了哈希冲突。

  - 优点：内存利用率更高，链表节点需要时动态创建即可，无需像开放寻址那样事先申请好；对大装载因子的容忍度更高。

  - 缺点：存储的记录随机分布在内存中，查询数组的时候，哈希表的跳转会带来额外的时间开销

  - 使用场景：大对象，大数据的散列表

  - 优化：用红黑树代替链表

- **开放寻址法**（√）

  解决方法是通过对哈希函数的改变，从而将可能发生哈希冲突的数按照一定规律哈希到另一个位置，用数组存储。

  - 优点：只用数组存储，易于序列化

  - 缺点：存储的记录数目不能超过桶的长度，否则需要扩容，对内存利用率不如链接法；冲突的代价更高

  - 使用场景：适用于数据量小，装载因子小的情况。

### 3. vector

实现：维护一个连续线性空间，因此支持随机存取，只需要三个指针，分别指向容器的第一个位置，最后一个元素所在位置，容器的最后一个位置。支持随机访问，头尾插入删除和访问时间复杂度都为`O(1)`，中间插入时间复杂度为

扩容方式：倍数开辟2倍的内存，旧的数据拷贝到新的内存中，释放旧的内存，指向新的内存

`vector`尾部插入和头部插入有什么区别？

`vector` 是一块连续的内存区域，如果在容器开头增加新元素，需要重新申请一块更大的空间，将原来的数据拷贝过来。

### 4. 树

- > 满二叉树：除了叶子节点外，其他节点都有子节点，是一个三角形。

- > **二叉查找树**
  >
  > 特点：小的放左边，大的放右边，查找的效率与树的高度相关
  >
  > 缺点：考验第一个根节点的取值，比如说根节点取1，那么就会出现“树”不分叉的情况。这种情况下，查找的效率最差，就跟链表一样了--`O(n)`。

- > **平衡二叉树（`AVL`）**
  >
  > 除了具有二叉查找树的特点外，最主要特点为左右两个子树的**层数最多相差1**，但是平衡二叉树追求的绝对平衡实现起来太苛刻，要维护起来操作次数不能预知。

- > **红黑树**
  >
  > ![image-20210829224603994](https://i.loli.net/2021/08/29/zZPy1QpqweKNmEx.png)
  >
  > 放弃了追求完全平衡，它追求的是大致平衡，保证每次插入最多只需要三次旋转就能达到平衡。查找、插入、删除时间复杂度`O(logn)`。什么是大致平衡？
  >
  > 缺点：无论为`AVL`的绝对平衡还是红黑树的大致平衡，其时间复杂度都与树的高度有关，**树的高度越高，需要检索的次数就越多。每次检索都需要将节点从磁盘加载到内存中，也就是说数据量越多，需要磁盘IO数量就越多。而且不支持范围查找。**

- > **`B`树【多叉平衡二叉树】**
  >
  > 与平衡二叉树的区别是：B树属于多叉树，节点也是左小右大的排列规则，所有叶子节点在同一层。
  >
  > **（数据库索引就是用它实现的）**
  >
  > `InnoDB`存储引擎一次`IO`操作读取一页 `==16 KB` 的数据量
  >
  > **定义**：通过在原来二叉树的每个节点多存储几个元素，以达到降低树的高度，从而减少`IO`操作次数。【每个元素（`8 Byte`）+左右指针（`4 Byte *2`）` ==  16 Byte`】这样原来的二叉树变成了多叉树【高瘦 --> 胖矮】。
  >
  > **优点**：相较于二叉树`1`次`IO`只能读`1`个元素，此时`1`次`IO`操作，可以读取`1000`个元素。空间利用率高了，时间效率也高了（数据的比较次数并没有明显减少【内存】，但是磁盘`IO`次数会大大减少）。
  >
  > ![在这里插入图片描述](https://raw.githubusercontent.com/SuZhaixing/img/master/img/20210418000634.png)
  >
  > `B`树特点：
  >
  > ① 节点中的元素包含键值和数据；
  >
  > ② 父节点当中的元素不会出现在子节点中；
  >
  > ③ 所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。
  >
  > **缺点**：
  >
  > ① 不支持范围查询的快速查找，如果我们想要查找`10`和`35`之间的数据，查找到`15`之后，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。
  >
  > ② 如果`data`存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘`IO`次数就会变大。

- > **`B+`树：改造`B`树**
  >
  > **与`B`树最主要不同**：只有叶子节点才会存储数据，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表；
  >
  > 
  >
  > <img src="https://raw.githubusercontent.com/SuZhaixing/img/master/img/20210418001551.png" alt="img"  />
  >
  > **`B+`树可以保证等值和范围查询的快速查找，`MySQL`的索引就采用了`B+`树的数据结构**；
  >
  > `B+`树的最底层**叶子节点包含了所有的索引项**。
  >
  > `B+`树在查找数据的时候，由于数据都存放在最底层的叶子节点上，所以每次查找都需要检索到叶子节点才能查询到数据。所以**查询数据时磁盘的`IO`次数跟树高有直接的关系**；
  >
  > 由于数据都被放到了叶子节点，所以**非叶子结点可以放更多的索引数量**；
  >
  > 相对于`B`树来说，`B+`树的树高理论上情况下是比`B`树要矮的。



### 6. 容器分类 实现总结

红黑树实现的四种关联式容器：`set`，`map`，`multiset`，`multimap`

### 7. 实际场景题

**如何计算两个微信号有多少个共同好友？**

需求详细如下：假设你有一个微信号（QQ号、手机号都可以，有关系链就可以），推荐你好友的好友给你作为“你可能认识的人”，推荐的时候通过共同**好友数量**来推断你们认识的可能性；

最简单的做法：拿出两个微信号的好友数据，进行交集运算，然后得到交集的数量。

缺点：非常耗费CPU，实际业务肯定不止计算两个用户，而是几百上千万用户，这样需要大量的机器来支撑。

我的算法：先找到UID的好友集合（Operator1），然后再找好友的好友（Operator2），这两部分和简单算法是一样的，但第三步不同，拿到两个集合后，并不进行集合交集运算，而是将好友的好友保存起来，用一个hash表记录UID以及一个数字，每次通过好友的好友找到某个用户，这个数字就加1，所以最终的算法就转换为计算有多少条路径到达某个用户，路径数量就是共同好友数量。

**地铁卡机如何计算两个站之间的费用**？

**姚晨发了微博，如何快速的推送给所有粉丝？**

### 8. 迭代器的作用

迭代器(iterator)是一种抽象的设计理念，通过迭代器可以在不了解容器内部原理的情况下遍历容器。stack 和 queue 不支持迭代器访问。

除此之外，STL中迭代器一个最重要的作用就是作为容器(vector,list等)与STL算法的粘结剂，只要容器提供迭代器的接口，同一套算法代码可以利用在完全不同的容器中，这是抽象思想的经典应用。**指针与迭代器的差别：**

迭代器：

> （1）：迭代器不是指针，而是类模板，表现的像指针，实际上他只是模拟了指针的一些功能，通过重载指针的一些操作符：->、*、++、-- 等封装了指针。是一个”可遍历STL容器内全部或部分元素“的**对象**，本质是封装了原生指针，是指针概念的一种提升，提供了比指针更高级的行为，相当于一种智能指针，它可以根据不同的数据结构来实现不同的++，–等操作；
> （2）：迭代器返回的是对象的引用而不是对象的值，所以cout只能输出解引用（*）迭代器之后的值
> （3）：在设计模式中有一种模式叫迭代器模式，简单来说就是提供一种方法，在不需要暴露某个容器内部的表现形式情况下，使之能一次访问容器的各个元素，这种设计模式在STL中得到了广泛应用，是STL的关键所在。通过迭代器，可以使容器和算法有机粘合在一起，只要算法给予不同的迭代器，就可以对不同的容器进行相同的操作；

指针：

> 指针能指向函数而迭代器不行，迭代器只能指向容器；指针是迭代器的一种。指针只能指向某些特定的容器；迭代器是指针的抽象和泛化；所以，指针满足迭代器的所有要求；

因此，迭代器与指针是由很大差别的，虽然他们的表现行为相似，但本质是不同的！

**指针是存放地址的变量，迭代器是类模板；**

注意：迭代器在使用后就释放了，不能再继续使用，但指针可以

### 9. 队列 优先队列

队列可以用线性表(list)或双向队列(`deque`)来实现(注意vector container 不能用来实现queue，因为vector 没有成员函数pop_front!)。普通的队列是一种先进先出的数据结构，元素在队列尾追加，而从队列头删除。

在优先队列中，元素被赋予优先级。当访问元素时，具有最高优先级的元素最先删除。优先队列具有最高级先出 （first in, largest out）的行为特征。**首先要包含头文件`#include<queue>`**, 他和`queue`不同的就在于我们可以自定义其中数据的优先级, 让优先级高的排在队列前面,优先出队。

优先队列具有队列的所有特性，包括队列的基本操作，只是在这基础上添加了内部的一个排序，它本质是一个堆实现的。

## 八. `Mysql`

### 1. **`SQL`书写执行顺序**

- 书写顺序

  **GROUP BY 书写在 WHERE 之后，HAVING 之前 **

  `SELECT`->`FROM`->`JOIN`->`ON`->`WHERE`->`GROUP BY`->`HAVING`->`ORDER BY`->`LIMIT`

  ```sql
  SELECT 查询列表
  FROM 表1
  【连接类型】JOIN 表2     
  ON 连接条件
  WHERE 筛选条件
  GROUP BY 分组列表
  HAVING 分组后的筛选结果
  ORDER BY 排序的字段
  LIMIT 起始的条目索引，条目数
  ```

- 执行顺序

  `FROM`->`ON`->`JOIN`->`WHERE`->`GROUP BY`->`HAVING`->`SELECT`->`ORDER BY`->`LIMIT`

  ```sql
  SELECT 查询列表            （7）
  FROM 表1                  （1） 
  【连接类型】JOIN 表2        （3）
  ON 连接条件                （2）
  WHERE 筛选条件             （4）
  GROUP BY 分组列表          （5）
  HAVING 分组后的筛选结果     （6）
  ORDER BY 排序的字段        （8）
  LIMIT 起始的条目索引，条目数 （9）
  ```

### 2. 编程

给了三个表：

- 学生基本信息表 `Student_Info`，包括：学生`ID`，学生姓名  ，学生性别（1-男，2-女））

  |  id  | name | gender |
  | :--: | :--: | :----: |
  |      |      |        |

- 专业信息登记表  `Subject_Register`，包括：专业`ID` ，学生`ID` 

  | subject_id | student_id |
  | :--------: | :--------: |
  |            |            |

- 专业基本信息表 `Subject_Info`，包括：专业`ID` ，专业名称

  |  id  | name |
  | :--: | :--: |
  |      |      |

![image-20210823115530586](https://i.loli.net/2021/08/23/ctEzOpoAsDwYdTS.png)

**要求：查询出女生数量最多的前三个专业名称和对应的女生数量。**

统计每个专业当中的女生数量得到一个中间表

<img src="https://i.loli.net/2021/08/23/ynoXVIHq6RrE24M.png" alt="image-20210823115310597"  />

- 只统计学生信息表中 `gender = 2` 中的行数 (`WHERE`)
- 以专业为组别，分别统计女生信息有多少行（`COUNT ... GROUP BY 专业ID`）
- 统计完后结果按照女生数量降序排列（`ORDER BY`）

```sql
SELECT subject_name, girl_counts                                 # 最终结果的表头：专业名称，女生数量
FROM                                                             # 中间表
( SELECT subject_id, COUNT(Student_Info.id) AS girl_counts       # 中间表的表头：专业ID，女生数量
  FROM Subject_Register                                          # 专业信息登记表与学生基本信息表内连接，以获取学生的性别    
  INNER JOIN Student_Info 
  ON Student_Info.id = Subject_Register.student_id
  WHERE Student_Info.gender = 2                                  # 限定只统计性别为女的行数
  GROUP BY Subject_Register.subject_id                           # 按照专业来统计行数
  ORDER BY girl_counts DESC                                      # 结果按照女生数量降序排列
)
AS Subject_GrilNum                                               # 中间表的表名
INNER JOIN Subject_Info                                          # 中间表与专业基本信息表内连接，以获取专业的名称
ON Subject_GrilNum.subject_id = Subject_Info.id
LIMIT 0, 3                                                       # 只保留前三行结果
```

最终得到表格：

![image-20210823121319043](https://i.loli.net/2021/08/23/871FsVKjOXgRpl9.png)

### 3. 为何数据库使用 B+ 树

### 4. 事务的 4 个隔离级别

### 5. 索引

### 6. MySQL 基本架构

MySQL 可以分为 Server 层和存储引擎层两部分。

Server 层包括：连接器、查询缓存、分析器、优化器、执行器等。

- **连接器**

  负责与客户建立、维持和管理连接、获取权限。

- **查询缓存**

- **分析器**

- **优化器**

- **执行器**

### 7. 查询优化



## 九. **设计模式**

### 1. 软件开发的流程

（1）需求分析

了解和分析用户的需求，列出要开发的系统的功能模块有哪些。（形成需求报告）

（2）概要设计

系统设计，考虑系统的处理流程、系统的组织结构、模块划分、功能分配、接口设计、运行设计、数据结构设计和出错处理设计，为软件的详细设计提供基础。（形成设计报告）

（3）详细设计

描述实现具体模块所涉及到的主要算法、数据结构、类的层次结构及调用关系。详细涉及应该足够详细，后续直接根据详细设计报告就能进行编码，设计过程完成的好，编码效率也会大大提高。

（4）编码

编写程序，实现各个模块的功能。

（5）测试

测试系统的每一个功能，证明软件是否达到要求。（形成测试报告）

（6）软件交付

开发者向用户提交开发的目标安装程序、数据库的数据字典、《用户安装指南》、《用户使用指南》、需求报告、设计报告、测试报告。

（7）验收

用户验收。

（8）维护

根据用户需求的变化或者环境的变化，对应用程序进行修改。

### 2. 责任链模式

一个普通员工发起一个请假申请，当请假天数小于3天时只需要得到主管批准即可；当请假天数大于3天时，主管批准后还需要提交给经理审批，经理审批通过，若请假天数大于7天还需要进一步提交给总经理审批。请问需要使用哪种设计模式来实现这个场景？

采用**责任链模式**实现一个事件需要多个对象处理的场景，对请求的发送者与接收者进行解耦，属于行为型模式。

### 3. 工厂模式

属于创建类模式。

**主要解决：**接口的选择问题。

**使用场景：**（1）日志记录器：记录可能记录到本地磁盘、系统时间、远程服务器等，用户可以选择记录日志到什么地方；（2）数据库访问：当用户不知道最后系统采用哪一类数据，以及数据库可能有变化时；（3）设计一个连接服务器的框架时，需要多个协议，可以将它们作为产品类，共同实现一个接口。

**优点：**面向接口编程，体现了面向对象的思想。将创建对象的工作转移到了工厂类，屏蔽了产品的具体实现，调用者只关心产品的接口。

**缺点：**使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。

**注意：**复杂对象适合使用工厂模式；而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。



描述

- 适配器模式属于结构型模式
- 原型模式属于创建型模式，实现了一个原型接口，用于创建当前对象的克隆
- 桥接模式属于结构型模式，用于将抽象化与实现化解耦，使得二者可以独立变化
- 策略模式属于行为型模式。意图是定义一系列算法，将其一个个封装起来，并使他们可互相替换

